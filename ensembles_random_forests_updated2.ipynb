{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    " \n",
    "# Ensembles and Random Forests\n",
    " \n",
    "_Author: Joseph Nelson (DC)_\n",
    "\n",
    "*Adapted from Chapter 8 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Students will be able to:\n",
    "\n",
    "- Understand how and why decision trees can be improved using bagging and random forests.\n",
    "- Build random forest models for classification and regression.\n",
    "- Know how to extract the most important predictors in a random forest model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Guide\n",
    "- [Introduction](#introduction)\n",
    "- [Part 1: Manual Ensembling](#part-one)\n",
    "- [Part 2: Bagging](#part-two)\n",
    "    - [Manually Implementing Bagged Decision Trees](#manual-bagged)\n",
    "    - [Bagged Decision Trees in `scikit-learn`](#manual-sklearn)\n",
    "    - [Estimating Out-of-Sample Error](#oos-error)\n",
    "    \n",
    "    \n",
    "- [Part 3: Random Forests](#part-three)\n",
    "- [Part 4: Building and Tuning Decision Trees and Random Forests](#part-four)\n",
    "    - [Predicting Salary With a Random Forest](#random-forest-demo)\n",
    "    - [Comparing Random Forests With Decision Trees](#comparing)\n",
    "    \n",
    "    \n",
    "- [Optional: Tuning Individual Parameters](#tuning)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Ensembling?\n",
    "\n",
    "**Ensemble learning** is the process of combining several predictive models in order to produce a combined model that is more accurate than any individual model. For example, given predictions from several models we could:\n",
    "\n",
    "- **Regression:** Take the average of the predictions.\n",
    "- **Classification:** Take a vote and use the most common prediction.\n",
    "\n",
    "For ensembling to work well, the models must be:\n",
    "\n",
    "- **Accurate:** They outperform the null model.\n",
    "- **Independent:** Their predictions are generated using different processes.\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when you average the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling works due to the concept of large numbers.\n",
    "Popularized by wisdom of the crowds.\n",
    "\n",
    "##### \"the average of the results obtained from a large number of trials should be close to the expected value, and will tend to become closer as more trials are performed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's take a random number from a standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4710700822676834"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The mean of a standard normal distribution is 0\n",
    "And 98% of the values should be within -2 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to the law of large numbers if we take the mean of a very large sample size we should be closer to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(1,50000, 100)\n",
    "y = [np.mean([np.random.normal() for o in range(i)]) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mean of samples')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.xlabel('# of Samples')\n",
    "plt.ylabel('mean of samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-one\"></a>\n",
    "## Part 1:  Ensembling Methods\n",
    "\n",
    "a. Voting <br>\n",
    "b. Averaging <br>\n",
    "c. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Classifiers: \n",
    "- Train independent models \n",
    "- Have them each predict from the data set\n",
    "- Make the final prediction be the majority vote choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/majority_vote.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Averaging\n",
    "\n",
    "Averaging Models: \n",
    "- Train independent models \n",
    "- Have them each predict from the data set\n",
    "- Make the final prediction the average of all the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/averaging.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Bagging\n",
    "\n",
    "An important aspect of ensembling and the law of large numbers is that each weaker model must be independent. If they are correlated in some way, the final prediction will be biased towards their relationship.\n",
    "\n",
    "Bagging increases the independence of the weaker learners by training them on different samples of the data.\n",
    "\n",
    "\n",
    "**Bagging** is a procedure for reducing the variance of a machine learning method.\n",
    "Bagging is short for **bootstrap aggregation**, meaning the aggregation of bootstrap samples.\n",
    "\n",
    "A **bootstrap sample** is a random sample with replacement. So, it has the same size as the original sample but might duplicate some of the original observations.\n",
    "\n",
    "**Bootstrapping** is taking these random samples with replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/baging_annotated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Population\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    }
   ],
   "source": [
    "# Set a seed for reproducibility.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create an array of 1 through 20.\n",
    "nums = np.arange(1, 21)\n",
    "print('Total Population')\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 12 13  9 10 12  6 16  1 17  2 13  8 14  7 19  6 19 12 11]\n",
      "[15 19  5 10 18  1 14 10 10  8  2  1 18  9 14 20 16 11  9  8]\n",
      "[ 4  7 18  4  5 18 12 13 17 14 20 10 19 16  1  5 16  3  8  9]\n",
      "[10  4  8  5  6 20  7  9  1  3 11 16 16  8 20 11 15  1  2 18]\n",
      "[14  4  1 14  7  7  3 13 12  8 14  9 12 13 12  5  8  8 14  5]\n",
      "[17 19  1 14 11 18  8 11  1 13  2 10 19 20  2  3 13  8  3 11]\n",
      "[ 1 10 19  7  3  8  8 17 16  6 18 11 17  6 14 18 19  2 11  1]\n",
      "[ 8  1 20 18 15 14 12  7 14 16 10  3  8  6  5  6  9 14 18 18]\n",
      "[16 14  9 15 14 17 11 14  4  3 15 15  1 12  4  2  3 20 17  1]\n",
      "[19 11  9 14  4  1  9 14 19 16 10  1 13 20 18 11 13 16 15 20]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.random.choice(a=nums, size=20, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "- Ensembling is means aggregating predictions from independent models to create a more accurate model.\n",
    "- Ensembling rests on the concept of law of large numbers, that the average of samples from a populations will approach the expected value the samples we have. Same concept between wisdom of crowds.\n",
    "- For classification, we take majority vote among the weaker learners.\n",
    "- For regression, we take the average\n",
    "- To increase independence between the models, we can train them in bootstrapped samples which are random samples from the population with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pt 2. Decision Tree Specific\n",
    "\n",
    "There are decision trees specific models that use the concepts of voting, averaging, and bagging.\n",
    "\n",
    "- Bagged Trees \n",
    "- Random Forrests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Bagged Trees\n",
    "\n",
    "Bagged trees use the idea of bagging and apply it to a collection of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How to train a bagged tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Grow B trees using B bootstrap samples from the training data.\n",
    "2. Train each tree on its bootstrap sample and make predictions.\n",
    "3. Combine the predictions:\n",
    "    - Average the predictions for **regression trees**.\n",
    "    - Take a vote for **classification trees**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/bagged_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "- **Each bootstrap sample** should be the same size as the original training set. (It may contain repeated rows.)\n",
    "- **B** should be a large enough value that the error seems to have \"stabilized\".\n",
    "- The trees are **grown deep** so that they have low bias/high variance.\n",
    "\n",
    "Bagging increases predictive accuracy by **reducing the variance**, similar to how cross-validation reduces the variance associated with train/test split (for estimating out-of-sample error) by splitting many times an averaging the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more trees and independence, the less variance because of the law of large numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mean of samples')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXecFdXZx3/PbVvpuxQpLiCKCApIUKxEUFGjGMsbjTFETSyJ6TEvJsaCJjFRYzS28BpjSWJNkdgQUaygFOmCFOlL210Wlm23PO8fM2fumbkz987dvdvY5/v57GennJk5M3fmPOcp5znEzBAEQRCE5hJo6woIgiAIhwYiUARBEIScIAJFEARByAkiUARBEIScIAJFEARByAkiUARBEIScIAJFEARByAkiUARBEIScIAJFEARByAmhtq5Aa1JSUsJlZWVtXQ1BEIQOxeLFi/cyc2mmcp1KoJSVlWHRokVtXQ1BEIQOBRFt9lNOTF6CIAhCThCBIgiCIOQEESiCIAhCThCBIgiCIOQEESiCIAhCThCBIgiCIOQEESiCIAhCThCBkgUH6qN4een2tq6GIAhCu6RTDWxsLje9uBxvrNqJ4X274qi+Xdq6OoIgCO0K0VCyYNu+WgBAQyze6tf+eGMFtlbWtvp1BUEQ/CICJQviCeN/gChtuZnvbcC1T+c2xcvXZi7Aqb9/J6fnFARByCVtKlCIaAoRrSWi9UQ03WV/HhE9b+7/mIjKHPsHEVENEf2sNerLzACAYCC9QPnNa2vw5updrVElQRCEdkObCRQiCgJ4GMA5AEYAuJyIRjiKXQOgipmPAHA/gN859t8P4PWWrqsinjAESiYNRRAEoTPSlhrKeADrmXkjMzcCeA7AVEeZqQCeMpdfAjCJyGjNiehCABsBrGql+iLBSqD4LG8KIEEQhM5AWwqU/gC2auvbzG2uZZg5BqAaQC8iKgLwvwDuaIV6Wij5EPApUeqire+8FwRBaCvaUqC4tcrOLr1XmTsA3M/MNRkvQnQtES0iokV79uxpQjWTKJNX0KfJ62BjrFnXEwRB6Ei05TiUbQAGausDAOzwKLONiEIAugGoBHACgEuI6PcAugNIEFE9Mz/kvAgzzwQwEwDGjRvXLBuUEih+T3KwIQ7IcBVBEDoJbSlQFgIYRkSDAWwHcBmArzvKzAIwDcB8AJcAeJuNUKtTVQEiuh1AjZswyTUqykv99yJAhnnsYINoKIIgdB7aTKAwc4yIbgQwG0AQwBPMvIqIZgBYxMyzAPwFwDNEtB6GZnJZW9UXAOLsT0MpjIRQ0xBDbaP4UARB6Dy0aeoVZn4NwGuObbdqy/UALs1wjttbpHIuqIGNGRQUFESCqGmIiYYiCEKnQkbKZ0HCkiTpJUphJAggd055CT8WBKEjIAIlCyynfCYNJWwIlE++qMzNdTNdUBAEoR0gAiULEj59KAWmhvL0/M3YXx8FAHxWvh9rdu5v1nUFQRDaMyJQsiDhU0Mpzku6purNwY3nPPA+pvzx/SZet0mHCYIgtCoiULIgGeWVXqKQPvAxB8qFmLwEQegIiEDJAuUbz9S+6+NUcuFPj4tTXhCEDoAIlCxQgiKTT0PfnQv/R6aBlIIgCO0BEShZ4DfKSzeJ5UKgiIYiCEJHQARKFujtem1jDM9+ssVVe9Cd6LlQLsSHIghCR0AEShNgBt5esxs3/2sFvth7MHV/jjUUkSeCIHQERKA0AQZbZqho3EVDYfflpiImL0EQOgIiUJoAc1LziLkNEsmxU14EiiAIHQERKE2AkTRDuckTXYjkwlwlI+UFQegIiEBpAsxsCQo3DYUdZZuLKCiCIHQERKA0AUZSaLhpDwkZ2CgIQidEBEoTYE5qHjEXp7xzYGNztRQxeQmC0BEQgdIkkiYvtzEi9tQr3GwNQzQUQRA6AiJQmgBzcqyJW2PPjrKxZgoE0VAEQegIiEBpAnqUl5tASTg0lGi8efnnJX29IAgdAREoTcDQUAxcnfIJIEBqv7ufJRsk9YogCB0BEShNIKGHDbs55QGEAsajZWZEm6liiA/l0OLhd9bj8pkL2roagpBz2lSgENEUIlpLROuJaLrL/jwiet7c/zERlZnbzySixUS0wvx/RmvWW/ehuGkozAxTnuREQ2nt9PU1DTFrdkoh99wzey3mb6xo62oIQs5pM4FCREEADwM4B8AIAJcT0QhHsWsAVDHzEQDuB/A7c/teAOcz8ygA0wA80zq1NmCwNb7EzeHObNdQmm3yasXGvaYhhpG3zcY9b65ttWsKgnBo0JYayngA65l5IzM3AngOwFRHmakAnjKXXwIwiYiImT9l5h3m9lUA8okor1VqDdi88l5Oed2Hopu8mqJttKYPpaY+BgD45+JtrXZNQRAODdpSoPQHsFVb32Zucy3DzDEA1QB6OcpcDOBTZm5wuwgRXUtEi4ho0Z49e3JScX2kvFfYcChoPNqEQ0NpirahyxPbGJcEY19tY9bnS0cy6aWYvARByI62FCjkss3ZiqUtQ0THwDCDXed1EWaeyczjmHlcaWlpkyqaes7MYcMBImtZDxtuirahX0Nf/tPb6zF6xhzsOeAqS5uEqmusmaHOgiB0PtpSoGwDMFBbHwBgh1cZIgoB6Aag0lwfAODfAL7JzBtavLYajGQ6FVeNg4GQafNyDmxsioaiCyF9+Y1VOwEAuw/Up68vMx54ax3W767JeK3GWKLJ9RQEoXPTlgJlIYBhRDSYiCIALgMwy1FmFgynOwBcAuBtZmYi6g7gVQA3M/OHrVZjE2M+FGPZTeNIMCMYSGooem8/njBSsWSjAegRV3oEslLfMik9lQcbcf9bn2PaE59kvFaDKVCiLgLl6F+9gQfnrst4DkEQOidtJlBMn8iNAGYD+AzAC8y8iohmENEFZrG/AOhFROsB/ASACi2+EcARAH5FREvNv96tVndk9qGosGFm+6yOiQQw6b55OPKW131fT7+ELsD0a6RDXb/RhxDzMnklEoy6aBx/mPO5jxoLgtAZCbXlxZn5NQCvObbdqi3XA7jU5bi7ANzV4hW0X9O2nM7klWBGUPOh6HOmxJmxqaLW1zXro3G8urwcRXnJn0m/HiF5jXTUReMAgHDAzSVlR5m8nLdVa54jE/9cvA3dC8OYdHQfX+UFob2SSDBiCUYkJOO//SJPyid6A6u3tTX1MWzae9BWlhmWyYsdAxtdpwz24O7X1+CnLy7Du5/vTtZDFyiUWh8nWytrUb6vDkAy8iwdXlpMbUPMWq5PI1x++uIyXPPUIs/976/bg/W7D2SsR0tzoD6KkbfNxvvrchP51xRk8Gj75tevfYYjb3ld/IlZIALFJ7bxI1qU131zPsfEe+c5ysLmQ9GjvLLJwrK3xojeqqhJhgbrJq+kD8X7hT/19+/g649/DAAIBVM1lFg8gY/W77XWvRJZ1mgCZdTtszNXXmPFtmorEu3Kv3yCyX94L6vjW4LPdx1ATUOsTU14kqMNeOKDL3DcHW+2dTVceWb+ZgBJrV3IjAgUn9hS0oPTmpmYGcGAGofiiPLKohFRQskukHQNhVLqlo5wIPXnfmDuOnz98Y+xcFMlAPvH81n5fsxZvQsAcLAhqZVE44bJb+X2al/XPf+hD3DOA+/7rGXrYD27NmzTpecLzHhlNarroq2eXigbmpuLrzMhAsUntlkYE+kb8QQDQSuXl1NDaYpAcRdIlsnL58fopqEooXCgPgogGeUFAOc88D6+87RhvjrYGLMd98yCzfjKnz7AB+v2wg9K2/LD22t2YbYZEu1ka2Ut7pm9ptnmokza3VMfbcJLzcgWUB+N4+Wl29P+NiJQkjS0Yy0g2o7r1t5oU6d8R4I1EaLPh+JVVjnlt1fVYZ02/iObEehqLIuuNeiNUCDLXrabD+Vgo6F5FISNVyHqkXfsYINdoKzavh8AsLXKCDCoqGmwaTHN4eonDSG26e7zUvb95IWlWLipCueM7IeR/bs1+RrJgafu+2+btQoAcMnxA5p0/kfnbcADc9dhW1Ud8kIBfPvUISllxOSVpCGWQH442NbVcMXrmxBSEYHiE2f6E3boKMyMhZuq8Mi89YjFGQFTGMx4ZbWtXLpeaV1jHLWNMVTXRREKBCyzWYOHD0b1sv32dN2ivGpNzSM/bFzLy15c4xAoyuSnTnn6PfNSyrQE6ndwCrhsUfV3/o65QkXW3TPbSLL5rZPKUgS6OOWTNMTiAMJtXQ1XPivfj77d8tu6Gh0CMXk1ATcNhRn48fNLMW/tHlQcbLS0Cye678VpDjn/oQ9w/F1v4Yz73sVp97xjnUNXuTdVHMT/vbcRQLKX7SVQnGNJ3ExetaaGok7h5ZR3ah+qvPJFeAmTXDeaBRGjF+s3jFmxbtcBXP/MYnxhRuQpTTGTeTxdRFs6SovtuUrdNFPJl5akIdp+zUpXPbkQcz/b1dbV6BCIQPGJXUNx2Q+gpEuyEQl6CBS98dcbFGZOSY3i5pT/5hOf4NevfYbquqilong1TM4Q4LCLyavOFCiqXl4aSq3Dh6KEYaaRLbl2aBaaAkXV2y8fbajAG6t24mcvLjPqZd5npiZ9hxlynS15YfuzdhPUHV1D2bGvDp9uqcKWilqUTX8Vryx3Zk7yT3v2oQDwlbZIEIHiG3bEeTkbA2ZGaXHEWvcjUPRGZltVasOlzuE1NiSTycspHNwEYa1ToLhci5nTmLzSi5SYLUuAvQJbK2uzTmxZGAnZ6u2HxZsrraADVW+VWiZTQIPzd1m8uRLvfp557Iqzx+1mh2+uD2X97gM5zzadCb1jMfHeefjqIx9hdbnhT3t5aXMESm78bzlFe7UzveeCgQgUnzg1FGdTwABKbRqK+6O1CZRYctktwaObyUuRSLAV5eWpoTiOcxMWdZbJy1tDicY5xWeRNHm5Xtoi5hGhBhhjZE74zVuex5ZNfzVlmzJ5KQEBGLnKNuxx70HO/WwXLn50Ph57124mVObATFkGnIL04kfn+8qJ5nzWbrnb1Lvw29c+w0cb/EXL6Uz+w3u46NGPsj6uqXy4fi9G3DobC8zZJtW7Ys390wSNS70/7V1DaSt58vqK8iabXdsCESg+Yceymw9FRUoBgIu7AoC9Uf3yffOsj9BtVkf1kbkJgriWIt9LQ3F+pG5mF3XuWBoNJRpPWNFgCmvelAwRMLa0M65pauzrzyzYbFt3ahAFZiTQ/jqjod9fH8XYO+dg0n3vujbaKs2NEgyqjHoWmfOgNS3k2/ns3Z5rImHc35/f24iv/9/Hvs+t12XjnoMZSvpj1Y5qXPPkwrSD+OZvMATJxxsrbdvVvTVF41LvcGv5UCpqGvCmR0g6AOw50IBPvjDuT/+EM2koT8/fhFG3z/Ydwn/uA+/jD45ZURtjCazZud9aX7CxAjf8fQl+98YaX+esa4xj9/70mcdbGhEoPrHn8kqNDmLYc3Z5aSh6o1R5sNFqyN0+xv0uY0P086h3vDkCxVkvdw0lkaKhqCs2pDknYNee0l1f8av/rLStO+9NPSb1bLZVJk1SWypTc6Q5P/BGUwAqE1QmDUUXmCpE2os5q3ehvNqoT0MsjkgwgDOG9045j3XuRMKKBsuEnj8OAGoacxtR9/OXlmPumt1Yu9M7LY6KXNxaVYtH5q1P1sWc5TOeYNRH47jokQ+xbOs+X9cNWBpK6/TCr35qEa59ZrFnEMlFj36I//nz/JTtXiZsxa0vr8KB+phrx2HdrgPYUlGLWDxhaXery/fjwbfX28pN/9dyTPnj+6g6aJgx99cZ7/gWn7n/vv/spxj/m7m+vrOWQgSKT5wj5d00FN1O7pU2y2meSjDj+YVbXHuoqhfu1sjHma3kkF75wZzH6Sa2lPMlVEPrz+SlGjevQV97axrQGEvYJxfT7t1vA+J8Xupe1cemD7j04zj1o6HYAyeS9Xea1dbtOmCZqmobY/jO04tw1V8XAjCefV4ogIvG9rddTyfBbDXGmRhx62yc9+AH1rq6/6aybOs+Wx4zlQCxMe79u6g29aXF2/D7N5K96wPmPSTM7AlLtuyzxvFkQr3Deufn0y1VeH1Fub8byZKN5m8Y99Cst5odFGdHxkdeVQDA7v0NKJv+Kv7+cVLTPvP+93DaPe9gxiurcdnMBfh8l7vQfmOloTkpYadP0ueHt8xItE+3+BPmLYEIFJ+k+FBcfmTd5OLVo3GaTRLm5FduqF64W2MUi2fWUJy9pXQ9l1gaDeVLv34rxXmu2lmvgIFxd72FGa+s8oxqO+DSkLo909mrdtq2K6FdbTaoek9zg4v5x/kxxhwmRrcnpz+nVTv2W9dyBgKcef97VkdAmZ6qTCd5YyyBSCiAkKmpujrlE8ABrf5XPL7ApTYGddE4Vpfvx1V//QSvryi3nl9TbPvMjKkPf4gr/5L0BUXMHlA6X0bQ42KV5j3rv/XSrfvwkxeWep4rkTA0Lt2HUlHTgLfX7MJXH/kIN/x9ia97+fen23B/FvnY1PeXKfrQ2eGhNA96l2ZmWrXDMFn9fcGWlHKvrTAERuXBZCCF3mao90tpreqSfi2t6jf8YH32/rhcIQLFL2xfTHHKs70h8rK5Ok1bCfa2PVfXRq0yThLM1kveVKd8wtbAG/mUvGzoy7dXY+JRpfjWSWXokh9K68RXLNpUZU8bo13PrYftdh8/fG4pVm5P2pXVB1hV24h9tY22Hv72fammAecpVX1Vg+LW+9Of09PzN+PymUZDn87Or7SX/t0LrOtEQgFEQqmh34p4gm2C9cP1FZjw27me1wCAd9buwYKNFdbzK2jC6HLV6OnkmedJ93sGPDpJFWZaHWcb/a8l2z3PNeQXr+EX/16h+VDi+M7Ti6wsCQAwb+1uLNlS5XkOAPjx88vwQBaTvqlvLZNZqN7xW6fzjZzwm+RvpsY59dIiPhVuyV7dojuVYElOJeHRPtRF8b1/LEFFTQMqahqs93ZbBtNsS5KVQCGiABF1banKtGdsqVfYxeQFts1y6DWw0alNvLV6F3btdw+dTTchVjzBlhruN2zY+RHVa72wm15ajsff/8LzmsxAUV4IoQBZ80S4nVNnzKAeNpORXna/i4bi5eCv0kJj1XUXbqrC6BlzLFNcgNxDiVM1FFOgOD7Wp+dvQtn0V1Efjac8NxUWqz+bn7+0zFretPcgPjR7hX26GiOqGxwairquLsTjiVSTV3l1vfV71jbGXBv46rqoJYhUupJ/Lt7mOxX/ZhebvOrdOhtSHa9O+l6zgYwzpz1eoZ7Bs59s1XwoiRQN81t/XYiLHslNFNszCzZj8eZKq4PRGEvg9lmrsHybu3nI6dvaU9OIN1ZmNsMpc1bPooh1HSd6Xjs1zkkXWGqqCFUHL1n27Cdb8Orycvz5vY3Yro2XyjYUP5dkFChE9A8i6kpERQBWA1hLRDe1fNXaF24CxLlfV1+9enPOxv9Hz3ubBdL1FhPMVhSKl4biVNudZhdnA/zKivK01yyOhBAMEGIJts6drnw4SPawYYdG5MTLF6T7b5wCTJm8SorzXMMrnfVT9VHPTP2ufzIdpNV1UU8hqZ/rhUXJxJET751nresDRPNCAWswaWMsNfgizoyahtTnoJ7tiFtn44KHPkjZv68uaplDlYby0xeX4cq/fILNFQexbtcBlE1/FYs3G9FKizdX4s/vbrCO3+/y7PNMH0pd1Nun4+V3UBpK3JzVU+dAfRQfb6xAfTRu/eZ6GUtDiSUyOr7TkS79UEMsjl/9ZyUufnS+Jcz21jTiyY824RuPu0fXOd+lB+euw/V/W2Izb7mhghqUgK520cT1Br+82jif/i0u3bYPzMlnuX1fXcrAYp14grHPtGb0KopkrGNL4kdDGcHM+wFcCGN2xUEArmzRWrVD9Nc14aqh2HvYfjWUdKTXUJJ23f8u24ELHzaiU/QXL8XkFUvg1eXlluBzjjYn85r5YffXoijPECgJrSearo7RONuEnW6fVwEHOl4aih6y7Hx+KiVMSXGeq4bibOAaLae8XaDo2p5u47Yd62OshLpeY9zQUMJBe+BE3KGhuPmSdNPamp0HUswt+2qjlsnL+Vttr6qzBl6+stzoUV/86Hz89vVkhmb92MWbK7FhT43llK9Jk+DTy7+iNJQEc0rD9/1nP8XXZi7ApPvexajbjXlPbL+TFuXlV6C49cDdOiiKdbuSwRRKI1WRVF4dv/po3FUje3P1LiTMaLa7X19jCVPFetP0qVIDVdelvku6hrLTbPz19/T3b6zFi4u2Wd/nF3sP4pt/SR37lMyYbXQyAODIPl0si0ciwXh9RTme+yTVn9NS+BEoYSIKwxAoLzNzFP6n4DhkcIYNO+UCs93k5emUzyJWP10DFk8kNZRPvqjE0q378MkXlVi8uQrMjA17alIa+5qGGL73jyV4zOytOhtgIkMDKM5zzxlalBfMSkOJxhM2rU3XNFQvWW8QvRyldg3F/vwO1EeRHw6gS37I+gCveHyB5ait1+4xFEhqTE4tRJmm6qNxWzSVTjrhqajT7N+RYFJDUdfTBexvVQodBzuq67CzOtnLdN6zm8lLoZsxnX489czV/0gwgIsfnY9J971r9ahr0yTd9BpgpxpzFTaso6ZH0E0yekdG3UdDNOHZCfv+s59ixTbjPC8s3Iov/fotfFZu9wO5PUdnHQrCQeu7rThoNLpe1/Qy3f3qPyvxt483428LNuOxdzfg/97/wrZffQ91jXFs2nsQc1bvTjmHLhDV7+zs3K3aUW17los2V6GmIWZrh9SziyUSqDbNwkf2KUZ1XRT10TiG/OI13PD3JZj+rxWu99IS+BEofwawCUARgPeI6HAAqV69Qxxb2DC7jUOxh9B6p17xf82MJi+XLlQkGMB/lm7HpPvexdzPki/zlGP6WsvKEejsTZJ5TW+BYmgozLAc5dF4wtNhGYsnbI2hLsBUA6BSqRjl3c+jR3I5zWJVtVEU54VQEAlaH+CH6yvwwNx12H2gHk9rAyV7FEWs42NWA2+O9ja/hH1pGiY/o7lVT7MhFjd8KEH7nDa62WjR5irXNC7nPfgBTtSc804tq7ouakWHOSMOG6IJS+tyvh2qZ6y0Q124qXqmy+Lsdf9Kg1y1Yz/W7swcul3rYlZriCU8A1n+u2wHbnx2CaLxBOaYobGbKw7i4XeS4zicAuUfH2/B9c8sBgB8UWH4ZvS54ZVWFfIYL9aQZnzQht01ls/Mq4N4sCGGiffOcx2UqH6HYIAsk5fTPB0KBlJ+95G3zcZfPkgKMBVdV3mw0TJ5DevTBUDb+VEyChRmfpCZ+zPzuWywGcCXc3FxIppCRGuJaD0RTXfZn0dEz5v7PyaiMm3fzeb2tUR0di7qkw79vfnpi8uw1TGIjtne2HmFWGYzp3wmp7zbJSKhgBVL//YaQ6B88otJGHFYMpZCNW4pJi8iNMYZRekEiuOixlgT948qmmCbiUdvrNQHENZSCniavHSB4ihTVduIorwQCsLBFI3rnD++b/vdehVFrNkmo5qvA0j25tPlxvIzdsYyecUSiISCVs8/6hBgChUVlA5n47avttF6Juv31NiithpiCVtnR/eXqEbULRxdPVdnRgRbPVzuP0B2M94TH9p77M72trou6trYNcTirtmwFZsrarGlstbqNISDAWtqAAD47WtrMGtZMpfYL/69Am+YI+KViU8XOsqsGQyQa6eoPs1vzQB2mmYlZzug8EoFBCQb+8ElRZa/o67RoTEHKWUbYI+cU2a7ippG7KuLoigStIIBWmMqCTf8OOX7ENFfiOh1c30EgGnNvTARBQE8DOAcACMAXG6eW+caAFXMfASA+wH8TqvDZQCOATAFwCPm+VoMp0aiYsq1AraG1a9TPh162aKI/fb+95/Lrel5dRLM6OF4qSKac9g4r6mWOxoqpaF4CZTivCCCjo8+GmdPwReLJ2xmLL3BVw23LiD8mbzsZd5esxv766IoiART7qfC4QvpUWg8l1iCLW1SCZSgJVDcNZQXFm3Fn818YOlQJrYG0ymv5kBR9+n8/d3CRp047yvByUapMZbAV/6UNNHVR+NJDYXsmQRUuKpqYKMuz/5gQwy79tfji70HUTb9VVz/zGIrEsrNDNStIP0cJs4e/MR73rGNf1FU10Y9O2GKgw0x6x1ydh7mb6zAD579FFMf/tCuscXiruYw5fvYc6ABx9w6G+c/9IHtuLrGhOfUBglm1Jna/SaPUex7a7w7Jmpfv2751jfqFGDxeGqAA2B/f5RQrDzYiOq6KLoVhC0TsnPK7dbKRODH5PUkgNkADjPXPwfwoxxcezyA9cy8kZkbATwHYKqjzFQAT5nLLwGYRIadZyqA55i5gZm/ALDePF/LkUEOpKRe8dJQMuS+8vpACx2N/BqPFBmNMbb5DQDYnMNA0tTh/CgXba7CZ+X70cVDoBRG7BpKl7wQGmIJz9HysTjb7lcf1a4abrdeshpdrtAdxW4RbaFgAAXhYMaU9qr3FtOCBZQwVB2AKg+B8vOXlqc9NwCcNaIPdlTX4xf/XpHilFe/V1PmQHFryMur3SN5GmIJS0gSEfZoDmDL5OUSCKB6vjUNMZzwm7n48r3zAABvrNqJCx76ENF4wjUTQSaB4tR4vJ7vxr0HbTa6r47pj/u/dhwAoHth2Kqbeme9AieWbd1nE9IHG+KuASCqs9EYT6AxnsDK7fuxVhvBXh+Ne3aUqutiliDYXJFZwxzWu9i2rs5b2iUPNQ0xfLR+L551OM4/cNkGJAU/M1v3uaO6DvtqG9GtMOI566Vb8EdL4EeglDDzCwASAMDMMQC5EHf9AWzV1reZ21zLmNetBtDL57E5JVMzYIQNa055R0/+9CNLAQD/+jT9POW/PO9o1+2FEX8K2Hvr9uDXr31m25YXCtpeNNXL8WqAvTWUkOUbygsFMKR3sfVBAsAJg3vayjfGE5Y2BNg1DdUguOX6ct6r3eSV+pH/9VtfQqGpobjtV1hjA7Q6R+PGVARKUFY3MR38dacPweCSIgCG/b4hmkCe5pR/7N0NGDPjzSalxXBzhqucYU5um7UK76w1TJ2NsYTNvKR65V6NMYAUZ7fi2qcXWeNxdAoi6Sd99RMZBxgmIr0jNKxPsfXsjjL9AjX1MetZeAnjaHJwAAAgAElEQVRUwJ7T7WCDMQPql8p62EzEbhqEbnX46YvLUvYrKmoarAbaLbJQzzr+8NfH4oXrJqSUiQQD6FEYQW1DDF9//OOUQaBeHcZ4gnH7rFUYcetsbN9Xh6P7dcWB+hg2VdSiW0EoRaBMGNILAHDD3xanjYTLFX4EykEi6gWzTSWiE2E07M3FrQvvbLe9yvg51jgB0bVEtIiIFu3Z42/gl5MD9VF8N0MqCIbd56FHj0wdfRjuvdTobS0wM7Ue3qvQ9TznjuqHL357bsr2iFdyMAePzttgW1dCoEt+8sNXpg6v2Pb8cMA1d1GRJlACRIgECY2xuPUBXzpuIN7+6elW+VicbWYVXdNQvWVdCCvhUuhopA42xjDlj+/htpdXuvprhpYWGxpKNJ7WcZ7UUOzRZ43xhKWhpHPKpyMcCNicvkkNJbmtqtYY2ZwtbqaPdCaVJabQqmuMW885PxzAnppG/OfT7Wn9Nm7pawBjhL5i4lGl1nJeyN97mY6yXoU4UB/DDk1I5IeCmHJMX9x8znDcdv4xAAwNRTXkukC9YeJQnDMyGXSi+zUO1BsC5bDuBbjlvKRF3RnuS2TML+OHndX1ad+zgT0KrOUxg7pbGpbOkNIiFOWF0vqsFKtnJF3E++uiePKjTdY7ccPEoQCMPHa9ivKQH7ILFDV18cJNVSnfVUvg5234CYBZAIYS0YcAngbw/RxcexuAgdr6AADOGXqsMkQUAtANQKXPYwEAzDyTmccx87jS0lK3Ihl57pOtWLw5fQoIZrt5RzcNFUaCtsYG8A5XDAUIRJQSJeY226IflCDRBUp5dR0aYwnPaXSNlCGp1yvOC1r1DgYIkVAACzZW4tLH5pt1JAwpLcamu8/DSUN7IZZI2MyAuqahTDG630Q18s5eVk1DDGt2HsBT8ze7BjXkhQIoiITADKxzmGWuOrkMQ0sNzcESKAn7b9UYT1jJPL18KJkIBwO2Yxui9iiv5tDU+TBqo3HsPdCAgnAQg3oWoqKmAYvMwY7f+/LQlPJ+hcPj3xyX9THpUJFJOgWRIELBAK47fajV41+ypcoSkOX7ksInEgzYGkvdIX7ug+9jS2UtuhWEbeY53RRYnBcyBwT6i4za5DBzDehRgEeuGIvLxw/CCYN74ktlSU29IBy0RWMqX+jwvl1QnJdqdXD7XfR7002GXfNDGNEvGWxTUhxJGZekMjcAmTMm5wI/UV5LAJwO4CQA1wE4hpkzG5QzsxDAMCIaTEQRGE72WY4ys5AMALgEwNtseM5mAbjMjAIbDGAYgMyzHjURp0PevYwzOWRAWyabDwPwFhBBrcG2l2/ay6BGUhfnJT+mVTv241f/Welp8goHA671K4yErJ48Ueo96I1LKBhA1KmhaHZc1dNkTprglIYScdyrbraJxRlnDO9tC20OBAgF5od04cMf2o49cUgvjOrfzRQ6yXxVujbZGEsknfJN1FBCQbLGNgCGn6JHYcS3ZpmO231m7nWiNJSSLhGUFOeh4mAjdu9vwJF9itGvW0FK+eF97Q37xWMHuGrSIe2e8pqQS8zJoJ6p19AbRvVbv7R4GwJkdHjK9yc1lLxwAEVa4+wcGwIYvp6uWqdKjxUo7ZKHgkjQdfoDnf+dMhzfOqnMGsuiOlf9uuXj3FH98NuLRuH56yZggHY/BRF3jWFYny6uGsO3TxliLd909lF45hrDNdzDRcsJBwMY2LPAsiaUFOeldMb6dM1LOa4l8Xzbiegi9QfgAgBHATgSwPnmtmZh+kRuhOHw/wzAC8y8iohmENEFZrG/AOhFROthaErTzWNXAXgBRiqYNwB8j5lbLIzBz1hEZjgGNib3hQKBlHh3T4FiNmzhHGkoqnPkHFvywfq9qKptdHXAR0IB14ZQDxsOBiild6rfYzhAiCUStqgUZyij0pqi8QRqGmJW9JEzQk53skYTCXQrCOPxaeNsZbwatkgogO6FEfTummcJ5Rv/scQaRQ4YAkVds6k+lHCQMLyvPc1dn675npqozuSj++Cj6Wd47veKJMpEXTSGPTUNKCnOQ6/iPCzeXIU3V+9Cn6757h0URyDJuLIeuHz8IADAaUe6a/fqHSgpjqQEU/zi3OG+6jl6YPeUbfq7pEyw9dEEhpQWo6xXoW3gp1NDcaOmIYauHgEEpcV5KAgHXcOZH71iLEb2N37XI/sUW9ouAIw9vAcApGg2uuByfiN/unwsLh47AOeN6uc63is/HMSdF47EcQO64bsTh+LUYcZz/3D6GXjsG2NtZYkIeaEgDjMTkpZ0SRUovYoNgdKvWz5ag3St1Plp/r6Si4sz82vMfCQzD2XmX5vbbmXmWeZyPTNfysxHMPN4Zt6oHftr87ijmPn1XNTHs56+yrBnLi93DcW9oQl4aijN6+nqJi8AGNq7GJ/vrMFRfVPNDXnBgKt6XBQJ2nwoRY6PeLf2QYbMPF76M3EKFGXKiCUYZ9//Hq41B6Kla4RjcUbINLfplO9zd1LnBQP40eRheObqE6xnuGyb3QX4xsqdlrPcKwopE+FgAN+dOBQnH9HL2ta7S57tObo1nIDRYB7WvQDLbz+rSdf2orYxjvLqevTtmo8SLfttaZc81/cpkWArWzJg9Ip7mWbCL5t+k5OG9rIdoxrMcDBgBVNcNLY/Nt19HroXpGbcBQwTkY5uIlKNrJ4QlIis7cN6F6NLftim+eaFAilh9deeNsS23q9bfkqwR2/z/Tu8V6FncMHAnoWWcOtWELYaaAC4+uTBAIDzj+tnO0YXXM7BxwN7FuC+/zkOZSVFVvCLLnTyQgFceeLhePnGU2zHFkZCGFJqjxZTr1ZZL0PIlZiCUWdY72J8bdxAPHlVywbBWnXy2sHMV6X5u7pVateRcEZ5aS+D8ovohDIICOf+cDNt1c7eUCQYwGc792N4v1SBEnYRKPlhY0yFLlAKHTbgMYOSDWYoGECjY6R8ikAxP85FmyptqTnSCc9onBEKBlJ6fhPNmRGd5IUNDaWspMhzVPSMV1Zby2p8zLLbsmvcQ0Hj+Yzs383a1qdrvu13Vw5UJ6pX6dcf0TXfn3O1tiGObVV1GNiz0P5M2f39iyUYr3z/FBxjDoItygth1IBu6N+9AGcd0xdr7pyCp6+2N0xKsIeCZGkJPc3xPt1czDQA8Mr3T8GbPz7NWtfNMreYUY6jtOeoX2dY7+IUM04oGEgxLd14xhHW8uwfnYarTx6MPIfDWjXEF40dgELzN8gPB2xBMQN7FFraevfCMEo0gdK3Wz7W3DkFPzvrKNt5u+Z7h1LrGoQy0+kC1mv8GmD3hwDJcVVlJYaJraQ4kvIOFeeF8LtLjnXtOLYEfgY29iKiB4loCREtJqIHzKivToMvkxfsUV4BIsuC4Nbbz+QTcR7j9Cs4meTRoKoGTQ8F/lJZD6zffQAH6mM4qm/qbASRUKpAUQIpKVBgaSjDehuO+KM1B2HYzJtlM3nVu2so3zJnOVSMH9zT9X4iwQBiiQTCwVRz29hBPXDXhSNdjkl+wOqZhwKEx74xFheOPiylvBqjke08I+r30aNsejsaPqdGp1D+gnT+lg81k5jeqKVj7a4DaIwlMKBHgS1ktC4aTzGpAoaG0qMogr9dcwJuOvsonDy0BMP7dsWH089A/+4FyA8HUwSRaqTDwYD1vivnt9cYle6FERzZp4v1jHWh+7UvDcS6X5+DMYN62I5RUW0jDuuKm8+xh9a7pT/Rn/VRfbsgFAxgcEkRxh2ePO8vzzsaT189HhOG9rK0l5LiPFt9uhWGETbntOlaELbNc1KcZ4TpOjuL3Qq8Bb4u2NU3NdDFh+SG3pH44aRheOzK4wEAg0sMzaV31/wUgeR3uEGu8NPVeQ7AewAuNtevAPA8gMktVan2hi+nPNvHVBAZQiXO7GrC8eotJ/c7NJoM5ft1d7eRqrPoJqIu+WEs3GRErfXrmnpcJBSwelK3nHc0/vrhppRggWCArF5hnkt24lAwkDJS3qmheDWMeaEAbj73aMxdY0+sFzcj6UKBgE1QKFSPzXkvCvUxF0aCmDKyH/LDQfxnqWtwYNZBEOr30XugylykcGp0iuTIdvdrRoIB2+9U7ENDKYwkU9EM7FGISUf3QU1DHHmhAH5wxjDXaWhVBF2Pogi+9+UjUvY7KQgHkyavQMDKkqzei3Q9dQBY8ItJlj350SvGorK2EUSp5mGdM4b3QSQUwLPfORGX/58x8Zkx+6O9nHpPzx2VDCeOhAJ48foJGHzzawCA/j0KcJxphsw366w6OeEgWdq1bvLStRx9vIlOpvtWKI1uYA9/AoWIcN3pQzDysG44/7hkZ+jScQNQUhyxmSsVXmPKWgo/V+vJzHdq63cR0YUtVaH2iB8N5cVFW229cb1xCLoIg0w+EWe4aaapXp0vTv/uBTYzko7uT3EzS4SDAavXrJzvyukdcvGhuD2fcDCAqCM811kfrw/SS3jGE4yahhjCwVQfCgDXeP+ILfLMqLvqGbqdQ5Fuylc3lElSf27O3rxX0s1Mg+f7drP3PI85rBuWb0s/FOyW80bgbws2Y3X5fvTvUYD+3Qvwp8vHWPs37k0d9Z7NIP5Ft0xGOBjAI/OMBI3hEFnhzepdcZqhnOgazDmj+qUpaZitiJK/2YShvTBtwuF4av5mz3RGq+44O0WTtWkf2vWVyUuZYRfcPMnqIIbNTAx5Zm62sYO649xR/Tw1MDfn/wvXTcCnjtknu5qazKCehRhcUuQrr5tTOwMMATZ1tPu47lyEdWeDH4HyDhFdBiOqCjDCd19tuSp1TO5zzGtNSGaBdRuLkKkH7GxUM6W9LwyHQGQ07ndccAxOHVaCM+57F0O0qBSF3rC5fRSRYMDqiSkHuIqZV0kUA4Fkj9tdoJAxgDBNK1XqoaFkGrvBcP9Q3ARKnpuG4uIMzcRdF47ELf9Z6blfmZCUhuI0mR3m4hRWJDK05CrUND8cQH00gdOPLHVNy2G7Xvd8PHn1l/DvJdtTUn8A7h2abPLMKe1SvSfBQMASKOre+3cvwDGHdXWdcjhb3HwASsjG2d33kKl3rj8Dy+RldnJ053skRNZ3QkT413dPTntet/Qn4wf3xHhHJoneXfJx76XHYfLRvfGNEw/3NT1CNjz2jbFZd4yai58v6joA/wDQaP49B+AnRHSAiDpdGnu/BCjZ43P3oSQf/as/OCVlv/OYTN+6Piq7d5c8DCktxswrj7dG6APAd04djFu/MgJdNJXcTaAwWOtpB1DaJQ99zXELqrEPahqKm7ALBQJWlJdX1JbXBx8OpoZZ63xWvt9Vu+hZlN7kpaqhIoLczGYAbBFR1nmCAXTND3lGailtRD03fRzF/JvPwBs/Ps3Th6I/P2cEFGAIIwB476Yv4+XvnYyzj+mDx74xFl851ujV/2jyMPzxa6Ntx/Tuko/eXfJx3elDXRsVt98kG4Gi0IXyV441zDDHm36KSCiAV39wqrWca1THKBwkXD5+YErYcjaoKC+3Ts6pw0pTIrlyxSXHD0D3wggKIsGMedGyZcrIlqlzOjJqKMzcOuEB7Riv+T7SQY4oLye6QHHr0TiPYWb8ePKRWLCxAvM3VqSUV2NHGmMJS2Ccpc2BAgC/NFNP6PNIuL3E8UTSuRwKEB68bIzVA7Q0FKK0Dr9wkHCgIYZH5m1A1/yQa0JCL00kFKC0ArS0OM+1gXJrDPRyKh14kYfJ6+QjeuHJq8a79t5DQcLy28/Gki1VrvOchx1Oef03VYMIvTK+6tMCDy4pSslA3M+0jffumo/epi9lysh+2FPTiFeWl+PUYSU4/vCeuPfNtdaxA3qmCiZbfV2eX3MECjNj8og+2HT3eSllPr/rHGypPIjJf3gv6/On44aJQ8FsOPLzQkHcd+lxKIqEcIFLsEUmlFblZoZVY3Gy5cg+qZrhoY4vjw0RHQugTC/PzP9qoTq1O/zIk+K8EGoaYjisWz52VNfbcmFlivJyi+5xHhNPMH44eRi+Vj3QNvmSdQ4ts23XNFEmgD1axE2YxZktR3swQFY6fCBpigsEkmGibs9HFxY/nzLcZi46qk8XnHxEiafZLxQIeJr4xgzqjhkXjnQPdHB5jnoPWsl45bx0CpQAUcYMBmEPzSlsaSipAiVZl8wmr2tPG4L31+217T/MY1DaN04YhJOG9sJQc3zCmz8+DdEYoygvNRorpb4u9xFvQsdJdRSOdokWVOhBHrmkMBLCz85OhuwSEe50ifTzd65klFcuWHnH2b4GtR5q+AkbfgLAEzCivHI6sLGj4OczIzJGPJ9gZvdEBg1Fb3C9oqR0VJvjZQmKaI7qTFEmfV3SbtiulWCrp+1s2NX1A6T5UFyekBI8F43pj2+ceLht36s/OAW3nj/C06wVClJKtubCSBDnjuqLx785DsV5IRARvnxUKR76+hjXcyh0YX3S0F6444JjcPsFRrJBp0BxzrXidj/qdyvtkmcbV6IEihJg2YQdj9VCWU8dVprSy/f6vYjIEiaA0cB2KwxnFCZA8j7CQcJT5tiSpmgoA0zh7PyNnbSEySuXFES8NZSmoEKK24Jnv3Mi/nbNCW1ybT8ayonM7Jz4SnCgJlRSzaBdQ3ERGNo2t56rUwipht1rnpW9NY1Wo+aVYkJx7IBuaffHE0kNxZlV1dJQiKxG060dSmpL9ro8ffV4q8HzNHkFCYGEfd9Xx/THr786yrbtrz5G/+qmRyLCtJPKrHWnZphurhqloajfpTgvhP+dMtzK7qzuJWA55/01oO/8bCLKPDJPA8A3JxyOU44o8XWubFDvSigQsBIMpkv978Ulxw/AxOGl6N0lfWqPvKAK6sj6EjnnpesnpPjbBvYsRCQUcM0r1tGYMLTthgn6eevnu8ykKDgwpnwNWA0YIb2GYh8fkbrfafLiNA5+wBACqoF0pllx4hxx62Ro72JLyDkz3QYtDSWZEdnNx6Siu5x10XNCeVlYwgH7wMp5P5toaRWZ+PmUozIXMknRUBySUc9/pCLIvEYyKxOSel7peqf9uuXj5CN6YeaVx2NwSZGr0/yKEwy7/S/POzpj+G1TsAZ5BsnqPDRBQUEgQBmFCQBrcKDXvPGtybiynilpTE4bVoJFt0zOmYbSWfGjoTwFQ6jsBNAAKyKWj23RmrUj/JqWI8GAZYfO5EPRhUym/UBSQ3E2aINLinD1KYNxydgBeHV5OQrCQV95v+68cKRr2OxNZx+F048sxfwNhuPfqaGoBiEYIGvg3tkO5z+QHBWvInH+ecOElMmIRg/sjq+NG4h31u625QELBMj2YpaVpIY+e/HdiUfguxOPQNn0zJHtzvuPO1Ljv/qDU7G54iA2V9Rak4fp0+vqqAZTmaAuOX6A6zWX3XoWwiHKmMxwxtSRuOnsozz9Ls1FaYmRYMAyb04+2j3bQi5QnR09b1d7goh8D0gUvPEjUJ4AcCWAFTBnbexs+BkpDxg9Xre5K9zHoSQbMzczlhIyamyJsm+7lb3StF+HQ5TRIe88xomaHU81tg0ec3EEyIjVX3TLZNcR6io9vYo4O/7w1IakyMwzdMFDH9gECpA+p1GucApep8mrZ1EEPYsitjQgShtTtVO/jzIFDuxZiA2/OddTk/TKb+UkGCB0d3muuSZk+t4W3DzJNew6d9cJ4JXvn+I5sZxwaOCn9dmisv92VnxrKKGANeWpfkimKK90GkooYKSA8DJ56U7zcDBgG2PSFJTwUwMi+zgijJLBAUY5r6iYAw1G7qhM5jfAffrN1sD5LNM55RVKY+hvpssoCBspTnR/TGtMZNRcVMfkcDNBYt9WSG8+sn96353Q8fEjUNYQ0T8A/BeGyQtA5wob9ovhQzGWdSGUKcTVdeCZ5jSNxuNJkxd5C5T8UBDBguY1ZqqnfcFxh6FHYSTFIexVD6/zuGkvTqafczR+9uIy/O7iY7FmZ27Gyr54/QTbnBl+SDeqXzGoVyEeuGw0Tjd9QUqg5GJmxtakb7d8/OnyMS3i8Bc6L34ESgEMQaLn82YAnUag+PVVRoJJp7xuJnOP8srUIBv7h/frgk+37MN3zPkdvJz1AHDTlKN8a1NeJE1t5DqpUiKN6U3ntvNH4Ki+XVLmz3BjwtBeVjbdU4blpoFriq3++tPd08s70fMmKed7U0Ju2xo9waAg5AI/I+Wvao2KtGt8ttJ54aSGorcvzsl/gMzJB1XD3rMwYhuX4JRDetXGOlJ+N4VMOcZU0EGmYJ1exXm+Mta2F9xGePvhNxeNwh3/XZWSql4QOiMZBQoR5QO4BsAxACxDa2eaZCsbDcVq8LWW3k+6cSdWVl+HBHEKokxJI7Mlk/1fTUrUlPQW7ZF/3jDBV9irF6cfWYq3fzoxdxUShA6Mn5buGQBrAJwNYAaM+VA+a8lKdVSMgY1Gg6xrKG5pyzNZ3JWZLJNpKdcCJdO8K4d1L8Dau6aknQwqV9x2/gjbpF0tgVv0mSAITcOPQDmCmS8loqnM/JTpoJ/d0hVrT2QT5RWwnPLN01DC1sjr9OVybbr341xuqbERTq4y5+wWBKFj4KebqeYO3UdEIwF0g5EosskQUU8imkNE68z/rsZ/IppmlllHRNPMbYVE9CoRrSGiVUR0d3Pq4odsxqEok5Te0HfJc0sRnx597va0dcu5htKxopUEQWg/+BEoM80G/xYAswCsBvD7Zl53OoC5zDwMwFxz3QYR9QRwG4ATAIwHcJsmeO5l5uEAxgA4mYjOaWZ90uJ/pHwwGTasbfeT1+mj6Wdgya/OtNZDPgVKLjSUH0waZi13hDEUgiC0TzK2dMz8ODNXMfN7zDyEmXsz82PNvO5UGCldYP53m1L4bABzmLmSmasAzAEwhZlrmfkds26NAJYAcM9z0cpENB+Krjn4mTXtsO4FtpHKahR3pgY+Fz6Un5x5pGVi85O2RRAEwQ0/6et/SERdyeBxIlpCRGdlOi4DfZi5HADM/25JhPoD2KqtbzO36XXrDiOdfuoEIW2A3YeSuj+bGeXUxFeZxjfkyuKVKfmkIAhCJvx0R69m5v0wBjb2BnAVgIx+CyJ6i4hWuvxN9Vk3t5bNaj6JKATgWQAPMvPGNPW4logWEdGiPXv2+Ly0x0UzYAxsNJbdNId7LzkOv/qKkbjZba53HTWpVXVdNG253Ed5iUARBKFp+Ak/Ui3MuQD+yszLyIcNh5kne56QaBcR9WPmciLqB2C3S7FtACZq6wMAzNPWZwJYx8x/zFCPmWZZjBs3rkmtb3ZRXqlOeUUgQLj65DKcMby367zlOiplSSaBkjMNxfzvZ3ImQRAEN/y0HouJ6E0YAmU2EXVB87MOzwIwzVyeBuBllzKzAZxFRD1MZ/xZ5jYQ0V0wos1+1Mx6+MJvlFcoQJb49dIciAiDS4oympZ6FBkmr/2tpKEon4+YvARBaCp+NJRrAIwGsJGZa4moFwyzV3O4G8ALRHQNgC0ALgUAIhoH4Hpm/jYzVxLRnQAWmsfMMLcNAPBLGIMtl5jK0kPM/Hgz69RsggGyRWW9/L2TrbmqnWSK3urZyiYvdZZMqVcEQRC88JPLKwEjkkqtVwCoaM5FzXNMctm+CMC3tXU1n71eZhtaO+N5Fm226uAnEozjBnZPUy6DhmKavPbXpxcoV+d48J9oKIIgNJXsh3B3QvzKkwAlNRS/Axe9UFPORl3mOf/WSWUYXFJkmx+9uQSJEGPOmOpFEATBC0+BQkSDmfmL1qxMe8XvaHRKulAymqIyKQIqvcmpLunc/c6vng3/+d7JeGPlTnHKC4LQZNJpKC8BOJ6I5jJzinmqM+HXTREgsvK6ZzrGz2DHhb+c7GvGw1wwsn83mVFPEIRmka61ChDRbQCOJKKfOHcy8x9arlodE6Kk5pELV3lpF5ljQxCEjkM6+8ZlAOphCJ0uLn+dBv8+lGTqEvFtC4LQ2fDUUJh5LYDfEdFyZn69FevUYQgHyeE0J1x98mDsOdCAa80pewVBEDoLfjywHxHRH1T6EiK6j4g6lbHdyx/inIwqQEBBJIjbLzgGhREJoBMEoXPhR6A8AeAAgP8x//YD+GtLVqq94TVS3pn3yo+jXRAE4VDFTzd6KDNfrK3fQURLW6pCHQnn7IbiNxEEoTPjR0OpI6JT1AoRnQygruWq1P7wMnkFU0xeIlEEQei8+NFQrgfwtOY3qUIysWOnRvJeCYIgJPGTy2sZgOOIqKu5vr/Fa9XO8Bopn2LyEpuXIAidGN+hSJ1RkGSiX7cCRGOMnfvrAbR2xkpBEIT2hSRu8oHXwMZIMIAHLx9jrYsPRRCEzowMlvCBl1NeS91lrWfD1NGHYUyaFPeCIAgdCV8ChYhOAlCml2fmp1uoTu2OdLMvkm09u/M+cNmYzIUEQRA6CBkFChE9A2AogKUA4uZmBtCJBIr7doJDQxEviiAInRg/Gso4ACPY76QghyBet24Ik6QQkSAvQRA6M36c8isB9G3pirRnPE1ecPpQRKIIgtB58aOhlABYTUSfAGhQG5n5gharVTvD2ylvN3KJhiIIQmfGj0C5vaUr0d7x8qEEyK6ViIYiCEJnxs9I+XdzfVEi6gngeRiRY5sA/A8zV7mUmwbgFnP1LmZ+yrF/FoAhzDwy13XU8XYfNS/KSxAE4VAiow+FiE4kooVEVENEjUQUJ6LmjpqfDmAuMw8DMNdcd163J4DbAJwAYDyA24ioh7b/IgA1zayHL7zDhu1CRAY2CoLQmfHjlH8IwOUA1gEoAPBtc1tzmApAaRtPAbjQpczZAOYwc6WpvcwBMAUAiKgYwE8A3NXMevgibdiwpqOIOBEEoTPjK/UKM68HEGTmODP/FcDEZl63DzOXm+cuB9DbpUx/AFu19W3mNgC4E8B9AGqbWQ9fiIYiCIKQGT9O+VoiigBYSkS/B1AOoCjTQUT0FtzDjX/ps25urTMT0WgARzDzj4mozEc9rgVwLQAMGjTI56UdF/V0yjtnbGzS6QVBEA4J/CHj1RkAABAHSURBVAiUK2FoMjcC+DGAgQAuTnsEAGae7LWPiHYRUT9mLieifgB2uxTbBrsmNADAPAATABxPRJvM+vcmonnMPBEuMPNMADMBYNy4cU0anOlXQxGBIghCZyajyYuZN8PQFvox8x3M/BPTBNYcZiE5Sdc0AC+7lJkN4Cwi6mE6488CMJuZH2Xmw5i5DMApAD73Eia5wntgIzl8KCJRBEHovPiJ8jofRh6vN8z10Wa4bnO4G8CZRLQOwJnmOohoHBE9DgDMXAnDV7LQ/Jthbmt1vJzySPGhtEp1BEEQ2iV+BzaOh2FuAjMv9eO7SAczVwCY5LJ9EYwoMrX+BIAn0pxnE4AWHYNiXsdzn6ReEQRBMPAT5RVj5uoWr0k7xktDicfZZuYSDUUQhM6MHw1lJRF9HUCQiIYB+AGAj1q2Wu0LLx9KLJEQDUUQBMHEj4byfQDHwEgM+SyA/QB+1JKVam94WbyicRY3vCAIgomfXF61MMaO+B0/csjhV0MRBEHozPiZsXEcgF8gdQrgY1uuWu2LdBqKJFwRBEEw8OND+TuAmwCsAJBo2eq0T7w0lHiCRUMRBEEw8SNQ9jBzc8eddGg8TV7xhOgngiAIJn4Eym3mYMO5sM/Y+K8Wq1U7wytsOBpniewSBEEw8SNQrgIwHEAYSZMXA+g0AsVrYGMsIRqKIAiCwo9AOY6ZR7V4TdoxXhpKLC4+FEEQBIWfcSgLiGhEi9ekHeMdNsySEFIQBMHEj4ZyCoBpRPQFDB8KAeDOFDbsraHIOBRBEASFH4EypcVr0c7x8qFEPdMQC4IgdD78jJTf3BoVac+kDRsWDUUQBAGAzznlOzteI+VjEjYsCIJgIQLFB54+lIQkhxQEQVCIQPGB7kN56foJeOn6CQAkOaQgCIKOH6d8p0f3oQwtLbaWo3EJGxYEQVCIhuKDE4f0spaJgHAoYFsXBEEQRKD4YsbU5LT1BEI4SNq6IAiCALSRQCGinkQ0h4jWmf97eJSbZpZZR0TTtO0RIppJRJ8T0Roiurj1Kg+EAwHbuiAIgtB2Gsp0AHOZeRiMLMbTnQWIqCeA2wCcAGA8jKzHSvD8EsBuZj4SwAgA77ZKrWGYuAIBXUMRiSIIggC0nUCZCuApc/kpABe6lDkbwBxmrmTmKgBzkBy1fzWA3wIAMyeYeW8L19dCFx/DeheLD0UQBMGkraK8+jBzOQAwczkR9XYp0x/AVm19G4D+RNTdXL+TiCYC2ADgRmbe1ZIVVqiBjK//8FT065aPuKRfEQRBANCCGgoRvUVEK13+pvo9hcs2hiEEBwD4kJnHApgP4N409biWiBYR0aI9e/ZkfR9elTq6X1d0L4zISHlBEASTFtNQmHmy1z4i2kVE/UztpB+A3S7FtgGYqK0PADAPQAWAWgD/Nre/COCaNPWYCWAmAIwbN67Z6oRTfog4EQRBMGgrH8osACpqaxqAl13KzAZwFhH1MJ3xZwGYzcaw9f8iKWwmAVjdstVN4nTCi4IiCIJg0FYC5W4AZxLROgBnmusgonHm/PVg5koAdwJYaP7NMLcBwP8CuJ2IlgO4EsBPW6viqRqKSBRBEASgjZzyzFwBQ7Nwbl8E4Nva+hMAnnAptxnAaS1ZR9+IPBEEQQAgI+WzJkVDEYEiCIIAQARK1qT4UNqoHoIgCO0NEShZkqqhiEgRBEEARKBkjVN8iDgRBEEwEIGSJU6NRBQUQRAEAxEoWZKqoYhEEQRBAESgZI1EeQmCILgjAiVLxAkvCILgjgiUZiLyRRAEwUAESjMRH4ogCIKBCJRmIhqKIAiCgQiUZiLyRBAEwUAESjMRJ70gCIKBCJRmIuJEEATBQARKMxEFRRAEwUAESjMRk5cgCIKBCBRBEAQhJ4hAEQRBEHKCCBRBEAQhJ4hAEQRBEHKCCBRBEAQhJ7SJQCGinkQ0h4jWmf97eJSbZpZZR0TTtO2XE9EKIlpORG8QUUnr1V4QBEFwo600lOkA5jLzMABzzXUbRNQTwG0ATgAwHsBtRNSDiEIAHgDwZWY+FsByADe2Ws0FQRAEV9pKoEwF8JS5/BSAC13KnA1gDjNXMnMVgDkApsAYnE4AisgYBNIVwI6Wr7IgCIKQjrYSKH2YuRwAzP+9Xcr0B7BVW98GoD8zRwHcAGAFDEEyAsBfvC5ERNcS0SIiWrRnz55c1V8QBEFw0GIChYjeIqKVLn9T/Z7CZRsTURiGQBkD4DAYJq+bvU7CzDOZeRwzjystLc36PgRBEAR/hFrqxMw82WsfEe0ion7MXE5E/QDsdim2DcBEbX0AgHkARpvn32Ce6wW4+GAEQRCE1qWtTF6zAKiorWkAXnYpMxvAWaYjvgeAs8xt2wGMICKlbpwJ4LMWrq8gCIKQgRbTUDJwN4AXiOgaAFsAXAoARDQOwPXM/G1mriSiOwEsNI+ZwcyVZrk7ALxHRFEAmwF8q7VvQBAEQbDTJgKFmSsATHLZvgjAt7X1JwA84VLuMQCPtWQdBUEQhOyQkfKCIAhCThCBIgiCIOQEESiCIAhCThCBIgiCIOQEESiCIAhCThCBIgiCIOSEthqH0uF49IqxWLG9uq2rIQiC0G4RgeKTc0b1wzmj+rV1NQRBENotYvISBEEQcoJoKDngtxeNwpF9urR1NQRBENoUESg54PLxg9q6CoIgCG2OmLwEQRCEnCACRRAEQcgJIlAEQRCEnCACRRAEQcgJIlAEQRCEnCACRRAEQcgJIlAEQRCEnCACRRAEQcgJxMxtXYdWg4j2ANjcxMNLAOzNYXU6AnLPnQO5585Bc+75cGYuzVSoUwmU5kBEi5h5XFvXozWRe+4cyD13DlrjnsXkJQiCIOQEESiCIAhCThCB4p+ZbV2BNkDuuXMg99w5aPF7Fh+KIAiCkBNEQxEEQRByggiUDBDRFCJaS0TriWh6W9cnW4joCSLaTUQrtW09iWgOEa0z//cwtxMRPWje63IiGqsdM80sv46IpmnbjyeiFeYxDxIRte4dpkJEA4noHSL6jIhWEdEPze2H7H0TUT4RfUJEy8x7vsPcPpiIPjbr/zwRRczteeb6enN/mXaum83ta4nobG17u/wWiChIRJ8S0Svm+iF9z0S0yXz3lhLRInNb+3i3mVn+PP4ABAFsADAEQATAMgAj2rpeWd7DaQDGAlipbfs9gOnm8nQAvzOXzwXwOgACcCKAj83tPQFsNP/3MJd7mPs+ATDBPOZ1AOe0g3vuB2CsudwFwOcARhzK923Wo9hcDgP42LyXFwBcZm5/DMAN5vJ3ATxmLl8G4HlzeYT5nucBGGy+/8H2/C0A+AmAfwB4xVw/pO8ZwCYAJY5t7eLdFg0lPeMBrGfmjczcCOA5AFPbuE5ZwczvAah0bJ4K4Clz+SkAF2rbn2aDBQC6E1E/AGcDmMPMlcxcBWAOgCnmvq7MPJ+NN/Fp7VxtBjOXM/MSc/kAgM8A9MchfN9m3WvM1bD5xwDOAPCSud15z+pZvARgktkTnQrgOWZuYOYvAKyH8R20y2+BiAYAOA/A4+Y64RC/Zw/axbstAiU9/QFs1da3mds6On2YuRwwGl8Avc3tXvebbvs2l+3tBtOsMQZGj/2Qvm/T9LMUwG4YDcQGAPuYOWYW0etp3Zu5vxpAL2T/LNqaPwL4OYCEud4Lh/49M4A3iWgxEV1rbmsX77bMKZ8eN9vhoRwW53W/2W5vFxBRMYB/AvgRM+9PYwo+JO6bmeMARhNRdwD/BnC0WzHzf7b35tb5bNN7JqKvANjNzIuJaKLa7FL0kLlnk5OZeQcR9QYwh4jWpCnbqu+2aCjp2QZgoLY+AMCONqpLLtllqrYw/+82t3vdb7rtA1y2tzlEFIYhTP7OzP8yNx/y9w0AzLwPwDwYNvPuRKQ6jno9rXsz93eDYRrN9lm0JScDuICINsEwR50BQ2M5lO8ZzLzD/L8bRsdhPNrLu93WDqb2/AdDg9sIw1GnnHLHtHW9mnAfZbA75e+B3YH3e3P5PNgdeJ+Y23sC+AKG866HudzT3LfQLKsceOe2g/slGLbfPzq2H7L3DaAUQHdzuQDA+wC+AuBF2B3U3zWXvwe7g/oFc/kY2B3UG2E4p9v1twBgIpJO+UP2ngEUAeiiLX8EYEp7ebfb/EVo738woiQ+h2GP/mVb16cJ9X8WQDmAKIzexzUw7MZzAawz/6sXiQA8bN7rCgDjtPNcDcNZuR7AVdr2cQBWmsc8BHOwbBvf8ykw1PTlAJaaf+ceyvcN4FgAn5r3vBLAreb2ITCidtabDW2euT3fXF9v7h+ineuX5n2thRbh056/BdgFyiF7z+a9LTP/Vqk6tZd3W0bKC4IgCDlBfCiCIAhCThCBIgiCIOQEESiCIAhCThCBIgiCIOQEESiCIAhCThCBIggaRPRbIppIRBdmm12WiErNLLafEtGpjn1fMbcvI6LVRHRdbmueUpfbiehnLXkNQXAiAkUQ7JwAI+/X6TAGB2bDJABrmHkMM1vHmqP2ZwI4n5mPg5FbbF5uqisI7QcRKIIAgIjuIaLlAL4EYD6AbwN4lIhudSl7OBHNNeeXmEtEg4hoNIwU4uea81QUaId0gTHqugIA2Mhqu9Y81/maVvMWEfUxt99ORE8R0Zvm/BcXEdHvzXkq3jCFlJob43dkzIXyCREd4VLfoeYxi4nofSIabm6/lIhWmlrTezl8nEInRQSKIABg5ptgCJEnYQiV5cx8LDPPcCn+EIyU4McC+DuAB5l5KYBbYcyxMZqZ67RzVwKYBWAzET1LRFcQkfr2PgBwIjOPgZGP6ufadYbCSJ0xFcDfALzDzKMA1JnbFfuZebxZrz+61HcmgO8z8/EAfgbgEXP7rQDONrWmCzI/JUFIj2QbFoQkY2CkaRkOYHWachMAXGQuPwNDM0kLM3+biEYBmAyjUT8TwLdgJN973kzoF4GRU0nxOjNHiWgFjNxSb5jbV8DIz6Z4Vvt/v35dM+PySQBe1LIt55n/PwTwJBG9AOBfEIRmIgJF6PSY5qonYTTuewEUGptpKYAJurbhga/8Rcy8AsAKInoGhuD4FoA/AfgDM88yU7Dfrh3SYB6XIKIoJ/MkJWD/dtljGTCsEPuYebRLfa4nohNgaDtLiWg0M1f4uRdBcENMXkKnh5mXmg2umir4bRimoNEewuQjGNlqAeAKGGYrT4ioWJuvAwBGA9hsLncDsN1cnoam8TXt/3x9BzPvB/AFEV1q1oWI6DhzeSgzf8zMt8IQpHo6c0HIGtFQBAFGyC+AKlMbGM7M6UxePwDwBBHdBGAPgKsynR7Az4nozzD8HwdhaCeAoZG8SETbASyAkSo9W/KI6GMYHcTLXfZfASPA4BYYUwM/ByNb7T1ENMys31xzmyA0Gck2LAgdGHNyqXHMvLet6yIIYvISBEEQcoJoKIIgCEJOEA1FEARByAkiUARBEIScIAJFEARByAkiUARBEIScIAJFEARByAkiUARBEISc8P/nklY3EB2f0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)\n",
    "plt.xlabel('# of Samples')\n",
    "plt.ylabel('mean of samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-three\"></a>\n",
    "#### b. Random Forests\n",
    "\n",
    "Random Forests offer a **slight variation on bagged trees** with even better performance.\n",
    "To add independence we also train the models on random set of features\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forrests randomize:\n",
    "- Data through bagging\n",
    "- It then bags the features: at every step of splitting it chooses the best feature out of a ramdom sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/random_forrest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building A Random Forrest Model\n",
    "\n",
    "- Exactly like bagging, we create an ensemble of decision trees using bootstrapped samples of the training set.\n",
    "- However, when building each tree, each time a split is considered, a **random sample of m features** is chosen as split candidates from the **full set of p features**. The split is only allowed to use **one of those m features**.\n",
    "    - A new random sample of features is chosen for **every single tree at every single split**.\n",
    "    - For **classification**, m is typically chosen to be the square root of p.\n",
    "    - For **regression**, m is typically chosen to be somewhere between p/3 and p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it create independence?\n",
    "\n",
    "- Suppose there is **one very strong feature** in the data set. When using bagged trees, most of the trees will use that feature as the top split, resulting in an ensemble of similar trees that are **highly correlated**.\n",
    "- Averaging highly correlated quantities does not significantly reduce variance (which is the entire goal of bagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Implementation of Bagged Decision Trees (with B=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in and prepare the vehicle training data.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = './data/insurance-med-expenses.csv'\n",
    "expense = pd.read_csv(path)\n",
    "expense.rename(columns={'expenses': 'med_expense'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sport</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>med_expense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex   bmi  sport  children smoker     region  med_expense\n",
       "0   19  female  27.9      3         0    yes  southwest     16884.92\n",
       "1   18    male  33.8      3         1     no  southeast      1725.55\n",
       "2   28    male  33.0      2         3     no  southeast      4449.46\n",
       "3   33    male  22.7      2         0     no  northwest     21984.47\n",
       "4   32    male  28.9      2         0     no  northwest      3866.86"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sport</th>\n",
       "      <th>children</th>\n",
       "      <th>med_expense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.665471</td>\n",
       "      <td>1.409567</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098382</td>\n",
       "      <td>1.009883</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.700000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.100000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.430000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi        sport     children   med_expense\n",
       "count  1338.000000  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.665471     1.409567     1.094918  13270.422414\n",
       "std      14.049960     6.098382     1.009883     1.205493  12110.011240\n",
       "min      18.000000    16.000000     0.000000     0.000000   1121.870000\n",
       "25%      27.000000    26.300000     1.000000     0.000000   4740.287500\n",
       "50%      39.000000    30.400000     1.000000     1.000000   9382.030000\n",
       "75%      51.000000    34.700000     2.000000     2.000000  16639.915000\n",
       "max      64.000000    53.100000     3.000000     5.000000  63770.430000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expense.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is A Continuous Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a26b02940>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "expense.med_expense.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables using get_dummies from Pandas.\n",
    "expense_dummies = pd.get_dummies(expense[['sex','smoker','region']])\n",
    "# Drop complimentary variables\n",
    "expense_dummies.drop(['sex_male','smoker_no'], axis=1, inplace=True)\n",
    "# Concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns).\n",
    "expense_dummies = pd.concat([expense, expense_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y. Include all variables except for variables \n",
    "# that we've encoded and the dependent variable.\n",
    "feature_cols = [x for x in expense_dummies.columns.values \n",
    "                if x not in ['sex','smoker','region','med_expense']]\n",
    "\n",
    "X = expense_dummies[feature_cols]\n",
    "y = expense_dummies.med_expense\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Bootstrapped Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1122, 1041,  106, ...,  411,  794,  998]),\n",
       " array([867, 893, 479, ..., 737, 718, 634]),\n",
       " array([ 216,   51,  419, ..., 1020, 1144,  482]),\n",
       " array([  12,  816,  341, ...,  712, 1258,  102]),\n",
       " array([410,  54, 722, ..., 240, 347, 987]),\n",
       " array([281, 809, 464, ..., 859,  65, 491]),\n",
       " array([1026, 1076, 1146, ...,  960,  282,  100]),\n",
       " array([1146,  923,  675, ...,  541,  308, 1000]),\n",
       " array([ 945,  300,  920, ...,  349,  529, 1082]),\n",
       " array([ 839,  355, 1133, ...,   49, 1224,  114])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a seed for reproducibility.\n",
    "np.random.seed(123)\n",
    "\n",
    "# Create ten bootstrap samples (which will be used to select rows from the DataFrame).\n",
    "samples = [np.random.choice(a=X_train.shape[0], size=X_train.shape[0], replace=True) for _ in range(1, 11)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sport</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>24</td>\n",
       "      <td>27.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>44</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>31</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>48</td>\n",
       "      <td>31.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>29</td>\n",
       "      <td>32.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   bmi  sport  children  sex_female  smoker_yes  region_northeast  \\\n",
       "1305   24  27.7      2         0           1           0                 0   \n",
       "913    44  27.5      1         1           1           0                 0   \n",
       "1324   31  25.9      2         1           0           0                 0   \n",
       "392    48  31.4      1         1           0           0                 1   \n",
       "189    29  32.1      2         2           1           0                 0   \n",
       "\n",
       "      region_northwest  region_southeast  region_southwest  \n",
       "1305                 0                 1                 0  \n",
       "913                  0                 0                 1  \n",
       "1324                 1                 0                 0  \n",
       "392                  0                 0                 0  \n",
       "189                  1                 0                 0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the rows for the first decision tree.\n",
    "X_train.iloc[samples[0], :].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Tree For Each Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Grow each tree deep.\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# List for storing predicted price from each tree:\n",
    "predictions = []\n",
    "\n",
    "# Grow one tree for each bootstrap sample and make predictions on testing data.\n",
    "for sample in samples:\n",
    "    X_train_sample = X_train.iloc[sample,]\n",
    "    y_train_sample = y_train.iloc[sample,]\n",
    "    treereg.fit(X_train_sample, y_train_sample)\n",
    "    y_pred = treereg.predict(X_test)\n",
    "    predictions.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions Of All Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9500.57,  4889.04, 28950.47,  9193.84, 34779.62,  4762.33,\n",
       "         2128.43, 14349.85, 23288.93, 11015.17, 20745.99,  7729.65,\n",
       "         3171.61, 45702.02, 49577.66, 45702.02,  8703.46, 42211.14,\n",
       "         7742.11, 37829.72,  4877.98,  7740.34,  1253.94,  2166.73,\n",
       "        11015.17, 10825.25, 12638.2 ,  4618.08,  9500.57,  1135.94,\n",
       "         7986.48, 12430.95,  2026.97,  4906.41,  3578.  , 32108.66,\n",
       "         2103.08,  6849.03, 22218.11, 38282.75, 24671.66,  2789.06,\n",
       "        11070.54, 12129.61,  4266.17, 11365.95,  3077.1 ,  4618.08,\n",
       "        40941.29,  4266.17, 28287.9 ,  1720.35,  7153.55,  1705.62,\n",
       "        11363.28, 10043.25,  4441.21, 39983.43, 11837.16, 10461.98,\n",
       "        14254.61,  4949.76, 14119.62,  7749.16, 10797.34,  3736.46,\n",
       "        19933.46],\n",
       "       [ 8603.82,  5267.82, 28950.47,  9282.48, 36898.73,  5846.92,\n",
       "         2128.43, 14410.93,  3353.47, 11015.17, 17361.77,  7729.65,\n",
       "         3766.88, 60021.4 , 48970.25, 42760.5 , 10118.42, 41676.08,\n",
       "         8547.69, 22331.57,  5615.37, 18806.15,  1261.86,  2741.95,\n",
       "        11015.17, 10435.07, 12638.2 ,  4260.74,  8444.47,  1135.94,\n",
       "         8059.68, 11830.61,  2007.95,  4134.08,  2632.99,  7935.29,\n",
       "         2585.27,  7345.73, 24520.26, 40273.65, 18838.7 ,  2639.04,\n",
       "        35160.13, 12347.17,  4673.39, 12347.17,  3591.48,  4906.41,\n",
       "        60021.4 , 18963.17, 14313.85,  1832.09,  6373.56,  1705.62,\n",
       "        11987.17, 10370.91,  3704.35, 38711.  , 11837.16, 10355.64,\n",
       "        13462.52, 18963.17, 12363.55,  7640.31, 10355.64,  3353.28,\n",
       "        16450.89]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(predictions)\n",
    "predictions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8851.128,  5003.133, 28500.572,  9131.081, 34930.832,  8484.491,\n",
       "        2107.991, 14240.109,  7389.371, 11139.764, 18619.065,  7176.982,\n",
       "        4060.039, 46656.125, 48401.958, 44520.048,  9791.423, 41883.74 ,\n",
       "       11098.308, 24996.98 ,  4959.945,  8869.139,  1644.536,  2287.342,\n",
       "       11492.323, 10919.106, 12751.18 ,  4373.96 ,  9277.356,  6835.083,\n",
       "        8079.198, 11790.924,  5513.323,  5015.668,  3262.939, 12744.654,\n",
       "        2350.642,  7230.033, 23725.136, 39359.313, 10596.795,  2472.857,\n",
       "       13329.092, 14182.146,  5659.2  , 16170.351, 14682.074,  4537.018,\n",
       "       43613.859,  6121.365, 15157.969,  1782.472,  6871.903,  1746.474,\n",
       "       14266.18 , 10062.224,  3718.098, 38288.877, 11750.834, 10597.53 ,\n",
       "       13578.557,  6048.143, 15913.992,  7697.12 , 11335.184,  5961.752,\n",
       "       16725.751])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average predictions.\n",
    "np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4866.228706632299"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE.\n",
    "from sklearn import metrics\n",
    "y_pred = np.mean(predictions, axis=0)\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"manual-sklearn\"></a>\n",
    "#### Bagged Decision Trees in `scikit-learn` (with Trees=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruct BaggingRegressor to use DecisionTreeRegressor as the \"base estimator.\"\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10015.75624   ,  5253.30272   , 28551.77736   , 12232.11268   ,\n",
       "       35021.71112   ,  9038.75764   ,  2046.34452   , 14479.36674   ,\n",
       "        6599.5704    , 11153.5447    , 19409.06286   ,  7034.99418   ,\n",
       "        6214.81      , 45691.50762   , 48495.32406   , 44515.78814   ,\n",
       "        9835.16768   , 43156.0232    ,  8840.04544   , 25601.10434   ,\n",
       "        5773.2151    ,  9595.5829    ,  2565.73713   ,  2638.941     ,\n",
       "       12274.0455    , 11220.94464   , 13439.0437    ,  5146.70602   ,\n",
       "       10599.77462   ,  5200.07694   ,  7772.31542   , 11830.40628   ,\n",
       "        2892.47668667,  5884.42888   ,  3366.14482   ,  8988.96024   ,\n",
       "        2881.13096   ,  7639.38736   , 23463.4547    , 39370.9076    ,\n",
       "        7506.69332   ,  3360.57866   , 12446.96786   , 15728.95496   ,\n",
       "        5817.12596   , 14868.57538   , 19026.0913    ,  6038.4788    ,\n",
       "       41728.363     ,  6262.24836   , 14094.03984   ,  2424.92786   ,\n",
       "        6869.38876   ,  1765.77866   , 13259.49816   , 10303.96532   ,\n",
       "        3771.86372   , 41109.71466   , 12059.75106   , 12415.21842   ,\n",
       "       13764.68228   ,  5316.69248   , 19892.61646   ,  7618.51398   ,\n",
       "       10615.77778   ,  4588.89476   , 17387.27234   ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and predict.\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4807.708440440287"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE.\n",
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pt 3. Ensemble Tree Methods\n",
    "\n",
    "- Out of Sample Error\n",
    "- Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are taking random samples with replacement (bootstrapped samples), there are going to be data points that are not in the training data of some models.\n",
    "\n",
    "We can these \"out of bag\" data points to test the accuracy of the models that were not trained by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"oos-error\"></a>\n",
    "#### a. Out-of-Sample Error\n",
    "We can calculate error metrics without using **train/test split** or **cross-validation**!\n",
    "\n",
    "By using the points that were excluded from the sample!<br>\n",
    "They are called \"out-of-bag\" observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1122, 1041,  106, ...,  411,  794,  998])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show \"in-bag\" observations for the first bootstrap sample.\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,    5,   22,   25,   28,   29,   30,   31,   33,   34,\n",
       "         45,   47,   52,   54,   55,   60,   69,   70,   74,   77,   78,\n",
       "         81,   82,   84,   93,   94,   99,  101,  102,  104,  107,  120,\n",
       "        124,  126,  127,  129,  130,  135,  137,  138,  142,  144,  145,\n",
       "        150,  152,  153,  156,  158,  159,  160,  162,  168,  174,  176,\n",
       "        177,  178,  179,  183,  184,  185,  189,  196,  199,  202,  205,\n",
       "        215,  216,  218,  220,  222,  223,  224,  226,  229,  230,  231,\n",
       "        232,  238,  240,  242,  244,  245,  251,  252,  253,  256,  262,\n",
       "        263,  265,  266,  267,  274,  278,  280,  284,  286,  289,  291,\n",
       "        292,  295,  298,  303,  304,  305,  310,  313,  315,  317,  318,\n",
       "        320,  321,  322,  324,  326,  327,  329,  330,  331,  332,  334,\n",
       "        336,  337,  338,  340,  353,  358,  359,  362,  370,  371,  374,\n",
       "        375,  376,  377,  378,  382,  383,  385,  387,  389,  390,  392,\n",
       "        398,  401,  404,  405,  407,  408,  411,  414,  418,  422,  425,\n",
       "        433,  436,  437,  439,  441,  442,  443,  444,  447,  449,  453,\n",
       "        454,  456,  460,  462,  463,  464,  467,  469,  471,  472,  473,\n",
       "        476,  477,  478,  483,  485,  487,  490,  491,  494,  495,  498,\n",
       "        499,  500,  503,  512,  513,  515,  518,  520,  521,  529,  536,\n",
       "        537,  539,  540,  541,  543,  551,  553,  555,  556,  560,  563,\n",
       "        568,  571,  572,  576,  583,  586,  587,  590,  594,  598,  601,\n",
       "        603,  605,  606,  608,  610,  612,  614,  615,  616,  620,  622,\n",
       "        625,  627,  636,  641,  647,  650,  651,  652,  654,  655,  657,\n",
       "        658,  661,  664,  668,  671,  673,  674,  677,  681,  684,  687,\n",
       "        688,  692,  700,  703,  706,  707,  709,  711,  713,  715,  717,\n",
       "        718,  722,  724,  727,  729,  731,  733,  734,  735,  738,  744,\n",
       "        745,  746,  748,  750,  751,  752,  753,  756,  761,  762,  774,\n",
       "        777,  780,  781,  782,  783,  786,  788,  790,  792,  793,  794,\n",
       "        795,  796,  805,  807,  808,  809,  812,  813,  814,  815,  816,\n",
       "        817,  818,  822,  824,  826,  827,  828,  829,  835,  836,  837,\n",
       "        840,  844,  849,  851,  854,  855,  857,  858,  860,  861,  864,\n",
       "        872,  874,  875,  876,  880,  887,  888,  890,  895,  898,  899,\n",
       "        903,  904,  905,  907,  908,  909,  912,  913,  915,  916,  919,\n",
       "        922,  924,  927,  933,  937,  940,  942,  943,  944,  953,  955,\n",
       "        956,  960,  965,  966,  967,  968,  970,  972,  978,  980,  983,\n",
       "        986,  990,  991,  992,  993,  996,  998,  999, 1006, 1010, 1011,\n",
       "       1012, 1014, 1015, 1016, 1019, 1022, 1023, 1027, 1034, 1039, 1043,\n",
       "       1045, 1046, 1047, 1048, 1050, 1052, 1053, 1054, 1058, 1059, 1060,\n",
       "       1062, 1067, 1068, 1069, 1071, 1073, 1077, 1079, 1081, 1083, 1085,\n",
       "       1086, 1087, 1095, 1097, 1099, 1105, 1109, 1113, 1117, 1122, 1124,\n",
       "       1125, 1127, 1128, 1129, 1131, 1136, 1137, 1143, 1147, 1148, 1149,\n",
       "       1150, 1156, 1158, 1159, 1161, 1162, 1163, 1169, 1175, 1176, 1178,\n",
       "       1179, 1185, 1186, 1189, 1191, 1193, 1194, 1197, 1198, 1199, 1205,\n",
       "       1210, 1211, 1212, 1214, 1215, 1216, 1217, 1222, 1223, 1230, 1232,\n",
       "       1233, 1238, 1241, 1246, 1250, 1256, 1264, 1266, 1267, 1268, 1269,\n",
       "       1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280,\n",
       "       1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291,\n",
       "       1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302,\n",
       "       1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313,\n",
       "       1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324,\n",
       "       1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335,\n",
       "       1336, 1337])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the \"out-of-bag\" observations for each sample.\n",
    "np.array(sorted(set(range(X.shape[0])) - set(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating \"out-of-bag error:\"**\n",
    "\n",
    "1. For each observation in the training data, predict its response value using **only** the trees in which that observation was out-of-bag. Average those predictions (for regression) or take a vote (for classification).\n",
    "2. Compare all predictions to the actual response values in order to compute the out-of-bag error.\n",
    "\n",
    "When B is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8400674875651636"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the out-of-bag R-squared score (not MSE, unfortunately) for B=500.\n",
    "bagreg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Estimating Feature Importance\n",
    "\n",
    "Bagging increases **predictive accuracy** but decreases **model interpretability** because it's no longer possible to visualize the tree to understand the importance of each feature.\n",
    "\n",
    "However, we can still obtain an overall summary of **feature importance** from bagged models:\n",
    "\n",
    "- **Bagged regression trees:** Calculate the total amount that **MSE** decreases due to splits over a given feature, averaged over all trees\n",
    "- **Bagged classification trees:** Calculate the total amount that **Gini index** decreases due to splits over a given feature, averaged over all trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Overview:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Bagging takes samples from data by taking each point with replacement, the samples of called bootstrapped samples\n",
    " - Bagged Trees means training one decision tree on each of these bootstrapped samples then averaging out the results for the prediction\n",
    " - For classification it is taking a vote of the most popular prediction and for regression is taking the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-four\"></a>\n",
    "## Part 4: Building and Tuning Decision Trees and Random Forests\n",
    "\n",
    "In this section, we will implement random forests in scikit-learn.\n",
    "\n",
    "This data was obtained by surveying the bank account holders. The purpose of the survey was to determine if account holders would purchase an additional product such as insurance marketed by the bank. Account holder either purchased an insurance product, or haven't, as indicated by `policy-purchase` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows - 48842\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>marr</th>\n",
       "      <th>occup</th>\n",
       "      <th>hered</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>sex</th>\n",
       "      <th>policy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Bachelor degree</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Indoor Sedentary</td>\n",
       "      <td>other-family</td>\n",
       "      <td>Australian</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Bachelor degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Qualified Professional</td>\n",
       "      <td>first-degree family</td>\n",
       "      <td>Australian</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Vocational training</td>\n",
       "      <td>Divorced/Separated</td>\n",
       "      <td>Light Trades</td>\n",
       "      <td>other-family</td>\n",
       "      <td>Australian</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Light Trades</td>\n",
       "      <td>first-degree family</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Bachelor degree</td>\n",
       "      <td>Married</td>\n",
       "      <td>Medical/Dental</td>\n",
       "      <td>first-degree family</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                 educ                marr                   occup  \\\n",
       "0   39      Bachelor degree       Never-married        Indoor Sedentary   \n",
       "1   50      Bachelor degree             Married  Qualified Professional   \n",
       "2   38  Vocational training  Divorced/Separated            Light Trades   \n",
       "3   53  Secondary education             Married            Light Trades   \n",
       "4   28      Bachelor degree             Married          Medical/Dental   \n",
       "\n",
       "                 hered      ethnic     sex  policy  \n",
       "0         other-family  Australian    Male       0  \n",
       "1  first-degree family  Australian    Male       0  \n",
       "2         other-family  Australian    Male       0  \n",
       "3  first-degree family       Asian    Male       0  \n",
       "4  first-degree family       Asian  Female       0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"data/bank-insurance.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df.drop(['first name','last name','email'], inplace=True, axis=1)\n",
    "df.columns = ['age','educ','marr','occup','hered','ethnic','sex','policy']\n",
    "\n",
    "print(\"Total number of rows - {}\".format(df.shape[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding variables\n",
    "non_cat_feats = ['age','policy']\n",
    "cat_feats = [col for col in df.columns \n",
    "             if col not in non_cat_feats]\n",
    "# Create a DataFrame of dummy variables\n",
    "df_dummies = pd.get_dummies(df[cat_feats], drop_first=True)\n",
    "\n",
    "# Concatenate the original DataFrame and the dummy DataFrame.\n",
    "df_dummies = pd.concat([df[[f for f in df if f not in cat_feats]], \n",
    "                        df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feat = 'policy'\n",
    "X = df_dummies[[c for c in df_dummies.columns if c != target_feat]]\n",
    "y = df_dummies[target_feat]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random-forest-demo\"></a>\n",
    "## Predicting Policy Purchase With a Random Forest\n",
    "\n",
    "### Fitting a Random Forest With the Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice the unbalanced class distribution in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29727\n",
       "1     9346\n",
       "Name: policy, dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will handle the unbalanced class distribution by assigning a weight to the `positive class` (1 - purchased policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the weights of the positive class\n",
    "denominator = y_train.value_counts().loc[1] / y_train.value_counts().sum()\n",
    "numerator = 1 - denominator\n",
    "\n",
    "positive_weight = int(round(numerator / denominator))\n",
    "positive_weight\n",
    "\n",
    "class_wgt = {\n",
    "    1: positive_weight,\n",
    "    0: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={1: 3, 0: 1},\n",
       "            criterion='gini', max_depth=None, max_features=5,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=150, n_jobs=None, oob_score=True, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features=5 is best and n_estimators=150 is sufficiently large.\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_features=5,\n",
    "    oob_score=True,\n",
    "    random_state=1,\n",
    "    class_weight=class_wgt)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.333315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>marr_Married</td>\n",
       "      <td>0.197873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>marr_Never-married</td>\n",
       "      <td>0.095727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hered_other-family</td>\n",
       "      <td>0.041986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sex_Male</td>\n",
       "      <td>0.036943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "0                  age    0.333315\n",
       "7         marr_Married    0.197873\n",
       "8   marr_Never-married    0.095727\n",
       "17  hered_other-family    0.041986\n",
       "21            sex_Male    0.036943"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute feature importances.\n",
    "pd.DataFrame({'feature': X_train.columns.values, \n",
    "              'importance': rf.feature_importances_}).sort_values(by='importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Accuracy Score:  0.7761625675018555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Compute the out-of-bag Accuracy score.\n",
    "print('OOB Accuracy Score: ', rf.oob_score_)\n",
    "\n",
    "# Find the average F1.\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=10, scoring='f1')\n",
    "print('Mean F1 CV Scores: ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the F1 Score on Training and Testing (more evaluating classification models in the next lesson!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY:  0.8440611163719193\n",
      "TESTING ACCURACY:   0.7794042378953834 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85      7428\n",
      "           1       0.53      0.74      0.62      2341\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      9769\n",
      "   macro avg       0.72      0.77      0.73      9769\n",
      "weighted avg       0.82      0.78      0.79      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('TRAINING ACCURACY: ', rf.score(X_train, y_train))\n",
    "print('TESTING ACCURACY:  ', rf.score(X_test, y_test), '\\n')\n",
    "\n",
    "y_test_preds = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare the performance of this model to the performance after some feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing X to its Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39073, 22)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of X_train.\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Feature Selection: \n",
    "\n",
    "Reducing the number of features can have an effect on the performance of the model. <br>\n",
    "\n",
    "Extra features introduce redundancies in data that can make the data be biased towards an outcome or overfit. <br>\n",
    "It also reduces training speed and accuracy for space based models (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'feature': X_train.columns.values, \n",
    "              'importance': rf.feature_importances_}).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.339053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>marr_Married</td>\n",
       "      <td>0.174130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marr_Never-married</td>\n",
       "      <td>0.092117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hered_first-degree family</td>\n",
       "      <td>0.061662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sex_Male</td>\n",
       "      <td>0.032344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importance\n",
       "0                         age    0.339053\n",
       "8                marr_Married    0.174130\n",
       "9          marr_Never-married    0.092117\n",
       "16  hered_first-degree family    0.061662\n",
       "21                   sex_Male    0.032344"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### One Option: Pick only the features above the mean feature importance (you can use median or based on your knowledge of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.339053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>marr_Married</td>\n",
       "      <td>0.174130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marr_Never-married</td>\n",
       "      <td>0.092117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hered_first-degree family</td>\n",
       "      <td>0.061662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importance\n",
       "0                         age    0.339053\n",
       "8                marr_Married    0.174130\n",
       "9          marr_Never-married    0.092117\n",
       "16  hered_first-degree family    0.061662"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_features_df = feature_importances[feature_importances.importance >= feature_importances.importance.mean()]\n",
    "mean_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_features = mean_features_df.feature\n",
    "X_train_imp_mean = X_train[mean_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Using only the features identified from `SelectFromModel`, let's re-train a new RandomForestClassifier on the training set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={1: 3, 0: 1},\n",
       "            criterion='gini', max_depth=None, max_features=3,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=150, n_jobs=None, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=150, max_features=3, random_state=1, class_weight=class_wgt)\n",
    "rf2.fit(X_train_imp_mean, y_train) # use feature importance input features of TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fit model and the features from the train data to transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9769, 4)\n"
     ]
    }
   ],
   "source": [
    "X_test_imp = slm_mean.transform(X_test)\n",
    "print(X_test_imp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Before Feature Selection & After"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY:  0.8440611163719193\n",
      "TESTING ACCURACY:   0.7794042378953834 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85      7428\n",
      "           1       0.53      0.74      0.62      2341\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      9769\n",
      "   macro avg       0.72      0.77      0.73      9769\n",
      "weighted avg       0.82      0.78      0.79      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('TRAINING ACCURACY: ', rf.score(X_train, y_train))\n",
    "print('TESTING ACCURACY:  ', rf.score(X_test, y_test), '\\n')\n",
    "\n",
    "y_test_preds = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY:  0.7394108463644973\n",
      "TESTING ACCURACY:   0.7412222335960692 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81      7428\n",
      "           1       0.48      0.82      0.60      2341\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      9769\n",
      "   macro avg       0.70      0.77      0.71      9769\n",
      "weighted avg       0.82      0.74      0.76      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING ACCURACY: ', rf2.score(X_train_imp_mean, y_train))\n",
    "print('TESTING ACCURACY:  ', rf2.score(X_test_imp, y_test), '\\n')\n",
    "\n",
    "y_test_preds = rf2.predict(X_test_imp)\n",
    "print(classification_report(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of the Change:\n",
    "\n",
    "In this case, the F1 decreased slightly for our target class (1). But this might not tell the whole story.\n",
    "\n",
    "**Although we lost overall performance from a machine learning perspective (F1 score), our recall improved overall which could be a benefit depending on the business problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing\"></a>\n",
    "## Comparing Random Forests With Decision Trees\n",
    "\n",
    "**Advantages of random forests:**\n",
    "\n",
    "- Their performance is competitive with the best supervised learning methods.\n",
    "- They provide a more reliable estimate of feature importance.\n",
    "- They allow you to estimate out-of-sample error without using train/test split or cross-validation.\n",
    "\n",
    "**Disadvantages of random forests:**\n",
    "\n",
    "- They are less interpretable.\n",
    "- They are slower to train.\n",
    "- They are slower to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning\"></a>\n",
    "## Optional: Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the model\n",
    "\n",
    "There are a number of things that we can tune when using RandomForests. \n",
    "One important tuning parameter is **n_estimators**, which represents the number of trees that should be grown. This should be a large enough value that the error seems to have \"stabilized.\"\n",
    "The other important tuning parameter is **max_features**, which represents the number of features that should be considered at each split.\n",
    "\n",
    "Using RandomizedSearchCV allows us to tune multiple parameter by fitting the model multiple times. \n",
    "**Please note that fitting the model 200 times would takes a few minutes to run. In fact, the number of model fits increases exponentially with the number of parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "###### HYPERPARAMETERS TO TUNE ######\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=200, num=5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 20, num = 5)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0631s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 15,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 2 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, random_state=42, n_jobs=-1,\n",
    "                               param_distributions=random_grid, \n",
    "                               n_iter=5, cv=2, verbose=10, scoring='f1')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 105, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 7, 'bootstrap': True}\n",
      "0.48183434959349586\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
      "0.5028268904205374\n",
      "{'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
      "0.48663677130044847\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': True}\n",
      "0.5073595843999398\n",
      "{'n_estimators': 57, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 7, 'bootstrap': True}\n",
      "0.46708423548819467\n"
     ]
    }
   ],
   "source": [
    "for i in  range(len(rf_random.cv_results_['params'])):\n",
    "    print(rf_random.cv_results_['params'][i])\n",
    "    print(rf_random.cv_results_['mean_test_score'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 105,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rf = RandomForestClassifier(**rf_random.best_params_)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('F1 score: %.2f' % metrics.f1_score(y_test, y_pred, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Ensembles: Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "\n",
    "Instead of voting or averaging\n",
    "\n",
    "Boosting involves training a seequence of models, with each model correcting it's predecessor. <br>\n",
    "This can be done by adding weigths to the misclassified datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Machine learning flowchart](assets/adaboost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Train Adaboost:\n",
    "- Give each point a weight of 1/n\n",
    "- Train a model and notice the points that were wrongly predicted\n",
    "- Increase the weights of the wrongly predicted and decrease for the correctly predicted\n",
    "- Train another model on these weights\n",
    "- Repeat the process until a stopping criteria (certain accuracy or # of trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others:\n",
    "- Gradient Boosting\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros and Cons of Boosting**\n",
    "#### Pros\n",
    "- Achieves higher performance than bagging when the hyperparameters are properly tuned.\n",
    "- Works equally well for classification and regression.\n",
    "- Can use \"robust\" loss functions that make the model resistant to outliers.   \n",
    "\n",
    "#### Cons\n",
    "- Difficult and time consuming to properly tune hyperparameters.\n",
    "- Cannot be parallelized like bagging (bad scalability when there are huge amounts of data).\n",
    "- Higher risk of overfitting compared to bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "\n",
    "**Which model is best?** The best classifier for a particular task is task-dependent. In many business cases, interpretability is more important than accuracy. So, decision trees may be preferred. In other cases, accuracy on unseen data might be paramount, in which case random forests would likely be better (since they typically overfit less). \n",
    "\n",
    "Remember that every model is a tradeoff between bias and variance. Ensemble models attempt to reduce overfitting by reducing variance but increasing bias (as compared to decision trees). By making the model more stable, we necessarily make it fit the training data less accurately. In some cases this is desired (particularly if we start with lots of overfitting), but for more simply structured data a simple decision tree might be best.\n",
    "\n",
    "---\n",
    "\n",
    "**In this lesson:**\n",
    "\n",
    "- We looked at ensemble models.\n",
    "\n",
    "- We saw how decision trees could be extended using two ensemble techniques -- bagging and random forests.\n",
    "\n",
    "- We looked at methods of evaluating feature importance and tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case: Titanic Datasets V2\n",
    "\n",
    "Increase the accuracy score of predicting survivors\n",
    "\n",
    "Here is the data dictionary: <br>\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "The current leaderboard has accuracy of 1. <br>\n",
    "https://www.kaggle.com/c/titanic/leaderboard\n",
    "\n",
    "Things to Try:\n",
    "- Random Forrest & Adaboost\n",
    "- Fill in null values (impute)\n",
    "- remove outliers in the data\n",
    "- be exhaustive with parameter tuning with RandomizedSearchCV\n",
    "- different weights for the unbalanced data sets\n",
    "- limiting to only the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "# Remove or impute null values\n",
    "features = ['survived', 'class', 'sex', 'age', 'sibsp', 'parch', 'fare',  'deck', 'embark_town']\n",
    "titanic['age'].fillna(titanic.age.mean(), inplace = True)\n",
    "titanic = titanic[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  class     sex   age  sibsp  parch     fare deck  embark_town\n",
       "0         0  Third    male  22.0      1      0   7.2500  NaN  Southampton\n",
       "1         1  First  female  38.0      1      0  71.2833    C    Cherbourg\n",
       "2         1  Third  female  26.0      0      0   7.9250  NaN  Southampton\n",
       "3         1  First  female  35.0      1      0  53.1000    C  Southampton\n",
       "4         0  Third    male  35.0      0      0   8.0500  NaN  Southampton"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing With Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "class            0\n",
       "sex              0\n",
       "age              0\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "deck           688\n",
       "embark_town      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suggestions\n",
    "\n",
    "- Fill Embark town with most popular town or try to use another column to guess (only two nulls)\n",
    "- Full deck null values as 0 and filled in values as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  class     sex   age  sibsp  parch     fare deck  embark_town\n",
       "0         0  Third    male  22.0      1      0   7.2500  NaN  Southampton\n",
       "1         1  First  female  38.0      1      0  71.2833    C    Cherbourg\n",
       "2         1  Third  female  26.0      0      0   7.9250  NaN  Southampton\n",
       "3         1  First  female  35.0      1      0  53.1000    C  Southampton\n",
       "4         0  Third    male  35.0      0      0   8.0500  NaN  Southampton"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make class categorical not continuous\n",
    "class_dummies = pd.get_dummies(titanic[[ 'class', 'embark_town']])\n",
    "titanic = pd.concat([titanic, class_dummies], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>class</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>class_First</th>\n",
       "      <th>...</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  class     sex   age  sibsp  parch     fare deck  embark_town  \\\n",
       "0         0  Third    male  22.0      1      0   7.2500  NaN  Southampton   \n",
       "1         1  First  female  38.0      1      0  71.2833    C    Cherbourg   \n",
       "2         1  Third  female  26.0      0      0   7.9250  NaN  Southampton   \n",
       "3         1  First  female  35.0      1      0  53.1000    C  Southampton   \n",
       "4         0  Third    male  35.0      0      0   8.0500  NaN  Southampton   \n",
       "\n",
       "   class_First           ...             class_Third  embark_town_Cherbourg  \\\n",
       "0            0           ...                       1                      0   \n",
       "1            1           ...                       0                      1   \n",
       "2            0           ...                       1                      0   \n",
       "3            1           ...                       0                      0   \n",
       "4            0           ...                       1                      0   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  class_First  class_Second  \\\n",
       "0                       0                        1            0             0   \n",
       "1                       0                        0            1             0   \n",
       "2                       0                        1            0             0   \n",
       "3                       0                        1            1             0   \n",
       "4                       0                        1            0             0   \n",
       "\n",
       "   class_Third  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "0            1                      0                       0   \n",
       "1            0                      1                       0   \n",
       "2            1                      0                       0   \n",
       "3            0                      0                       0   \n",
       "4            1                      0                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['age', 'fare']\n",
    "\n",
    "X = titanic[feature_names]\n",
    "y = titanic['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 57,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 11,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "###### HYPERPARAMETERS TO TUNE ######\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=200, num=5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 20, num = 5)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Random search of parameters, using 2 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, random_state=42, n_jobs=-1,\n",
    "                               param_distributions=random_grid, \n",
    "                               n_iter=50, cv=2, verbose=10, scoring='accuracy')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6811377245508982\n",
      "{'n_estimators': 105, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': False}\n",
      "0.6706586826347305\n",
      "{'n_estimators': 57, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 11, 'bootstrap': True}\n",
      "0.6976047904191617\n",
      "{'n_estimators': 152, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': False}\n",
      "0.6766467065868264\n",
      "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6841317365269461\n",
      "{'n_estimators': 57, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': False}\n",
      "0.6631736526946108\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': True}\n",
      "0.6856287425149701\n",
      "{'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 7, 'bootstrap': True}\n",
      "0.6706586826347305\n",
      "{'n_estimators': 105, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6856287425149701\n",
      "{'n_estimators': 57, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6856287425149701\n",
      "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': True}\n",
      "0.6901197604790419\n",
      "{'n_estimators': 152, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': False}\n",
      "0.6796407185628742\n",
      "{'n_estimators': 57, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 15, 'bootstrap': False}\n",
      "0.6736526946107785\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 7, 'bootstrap': True}\n",
      "0.6721556886227545\n",
      "{'n_estimators': 57, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 11, 'bootstrap': False}\n",
      "0.6631736526946108\n",
      "{'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': False}\n",
      "0.6676646706586826\n",
      "{'n_estimators': 152, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': True}\n",
      "0.6811377245508982\n",
      "{'n_estimators': 105, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
      "0.6841317365269461\n",
      "{'n_estimators': 105, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
      "0.6796407185628742\n",
      "{'n_estimators': 105, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': True}\n",
      "0.687125748502994\n",
      "{'n_estimators': 57, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 11, 'bootstrap': True}\n",
      "0.6901197604790419\n",
      "{'n_estimators': 57, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': False}\n",
      "0.6676646706586826\n",
      "{'n_estimators': 152, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 11, 'bootstrap': False}\n",
      "0.6646706586826348\n",
      "{'n_estimators': 152, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 15, 'bootstrap': True}\n",
      "0.687125748502994\n",
      "{'n_estimators': 105, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 7, 'bootstrap': False}\n",
      "0.6721556886227545\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 15, 'bootstrap': True}\n",
      "0.6901197604790419\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6661676646706587\n",
      "{'n_estimators': 105, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': False}\n",
      "0.6706586826347305\n",
      "{'n_estimators': 152, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 11, 'bootstrap': False}\n",
      "0.6661676646706587\n",
      "{'n_estimators': 105, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': False}\n",
      "0.6841317365269461\n",
      "{'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 11, 'bootstrap': True}\n",
      "0.6736526946107785\n",
      "{'n_estimators': 57, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': False}\n",
      "0.6781437125748503\n",
      "{'n_estimators': 152, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': True}\n",
      "0.6946107784431138\n",
      "{'n_estimators': 57, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': False}\n",
      "0.6901197604790419\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': False}\n",
      "0.6646706586826348\n",
      "{'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 11, 'bootstrap': False}\n",
      "0.6661676646706587\n",
      "{'n_estimators': 152, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6916167664670658\n",
      "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': False}\n",
      "0.6751497005988024\n",
      "{'n_estimators': 57, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
      "0.6946107784431138\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 11, 'bootstrap': True}\n",
      "0.6916167664670658\n",
      "{'n_estimators': 152, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': True}\n",
      "0.6901197604790419\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 11, 'bootstrap': True}\n",
      "0.6811377245508982\n",
      "{'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': True}\n",
      "0.6646706586826348\n",
      "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 15, 'bootstrap': False}\n",
      "0.6676646706586826\n",
      "{'n_estimators': 105, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 11, 'bootstrap': False}\n",
      "0.6691616766467066\n",
      "{'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 7, 'bootstrap': False}\n",
      "0.6736526946107785\n",
      "{'n_estimators': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 11, 'bootstrap': True}\n",
      "0.6721556886227545\n",
      "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 3, 'bootstrap': False}\n",
      "0.6841317365269461\n",
      "{'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 3, 'bootstrap': False}\n",
      "0.6856287425149701\n",
      "{'n_estimators': 105, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': False}\n",
      "0.6691616766467066\n"
     ]
    }
   ],
   "source": [
    "for i in  range(len(rf_random.cv_results_['params'])):\n",
    "    print(rf_random.cv_results_['params'][i])\n",
    "    print(rf_random.cv_results_['mean_test_score'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can Add Weights to the Unbalanced Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = round(549/342)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_wgt = {\n",
    "    1: 2,\n",
    "    0: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rf = RandomForestClassifier(**rf_random.best_params_, class_weight=class_wgt)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy score: %.2f' % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Predictive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3a36ecc0>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame({'features': X.columns, 'importance': rf.feature_importances_})\\\n",
    "                    .sort_values('importance', ascending= False)\n",
    "sns.barplot(x = 'importance', y = 'features', data = plot_df.head(10), orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do Feature Selection Using Only The Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'feature': X_train.columns.values, \n",
    "              'importance': rf.feature_importances_}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "mean_features_df = feature_importances[feature_importances.importance >= feature_importances.importance.mean()]\n",
    "mean_features_df\n",
    "mean_features = mean_features_df.feature\n",
    "X_train_imp_mean = X_train[mean_features]\n",
    "X_test_imp_mean = X_test[mean_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=1, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=150, max_features=1, random_state=1)\n",
    "rf2.fit(X_train_imp_mean, y_train) # use feature importance input features of TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.64\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf2.predict(X_test_imp_mean)\n",
    "\n",
    "print('Accuracy score: %.2f' % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can Save Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pkl.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
