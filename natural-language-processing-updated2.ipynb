{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    " \n",
    "# Natural Language Processing\n",
    " \n",
    "_Authors: Kiefer Katovich (San Francisco), Joseph Nelson (Washington, D.C.)_\n",
    " \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "- Discuss the major tasks involved with natural language processing.\n",
    "- Discuss, on a low level, the components of natural language processing.\n",
    "- Identify why natural language processing is difficult.\n",
    "- Demonstrate text classification.\n",
    "- Demonstrate common text preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='textblob_install'></a>\n",
    "\n",
    "### Install TextBlob\n",
    "\n",
    "The TextBlob Python library provides a simplified interface for exploring common NLP tasks including part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "To proceed with the lesson, first install TextBlob, as explained below. We tend to prefer Anaconda-based installations, since they tend to be tested with our other Anaconda packages.\n",
    "\n",
    "**To install textblob run:**\n",
    "\n",
    "> `conda install -c conda-forge textblob`\n",
    "\n",
    "**Or:**\n",
    "\n",
    "> `pip install textblob`\n",
    "\n",
    "> `python -m textblob.download_corpora lite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB         # Naive Bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So Far The Data We have Has Been Numerical or Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But What if Have Text Data Like Restaurant Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      5  My wife took me here on my birthday for breakf...\n",
       "1      5  I have no idea why some people give bad review...\n",
       "2      4  love the gyro plate. Rice is so good and I als...\n",
       "3      5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4      5  General Manager Scott Petello is a good egg!!!..."
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'./data/yelp.csv'\n",
    "yelp = pd.read_csv(path)\n",
    "yelp[['stars', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal Is to Represent Text With Numbers While Capturing As Much Information As Possible\n",
    "### This Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Enables a New Set Of Use Cases\n",
    "\n",
    "\n",
    "- **Chatbots:** Understand natural language from the user and return intelligent responses.\n",
    "    - [Api.ai](https://api.ai/)\n",
    "- **Information retrieval:** Find relevant results and similar results.\n",
    "    - [Google](https://www.google.com/)    \n",
    "- **Information extraction:** Structured information from unstructured documents.\n",
    "    - [Events from Gmail](https://support.google.com/calendar/answer/6084018?hl=en)\n",
    "- **Machine translation:** One language to another.\n",
    "    - [Google Translate](https://translate.google.com/)\n",
    "- **Text simplification:** Preserve the meaning of text, but simplify the grammar and vocabulary.\n",
    "    - [Rewordify](https://rewordify.com/)\n",
    "    - [Simple English Wikipedia](https://simple.wikipedia.org/wiki/Main_Page)\n",
    "- **Predictive text input:** Faster or easier typing.\n",
    "    - [Phrase completion application](https://justmarkham.shinyapps.io/textprediction/)\n",
    "    - [A much better application](https://farsite.shinyapps.io/swiftkey-cap/)\n",
    "- **Sentiment analysis:** Attitude of speaker.\n",
    "    - [Hater News](https://medium.com/@KevinMcAlear/building-hater-news-62062c58325c)\n",
    "- **Automatic summarization:** Extractive or abstractive summarization.\n",
    "    - [autotldr](https://www.reddit.com/r/technology/comments/35brc8/21_million_people_still_use_aol_dialup/cr2zzj0)\n",
    "- **Natural language generation:** Generate text from data.\n",
    "    - [How a computer describes a sports match](http://www.bbc.com/news/technology-34204052)\n",
    "    - [Publishers withdraw more than 120 gibberish papers](http://www.nature.com/news/publishers-withdraw-more-than-120-gibberish-papers-1.14763)\n",
    "- **Speech recognition and generation:** Speech-to-text, text-to-speech.\n",
    "    - [Google's Web Speech API demo](https://www.google.com/intl/en/chrome/demos/speech.html)\n",
    "    - [Vocalware Text-to-Speech demo](https://www.vocalware.com/index/demo)\n",
    "- **Question answering:** Determine the intent of the question, match query with knowledge base, evaluate hypotheses.\n",
    "    - [How did supercomputer Watson beat Jeopardy champion Ken Jennings?](http://blog.ted.com/how-did-supercomputer-watson-beat-jeopardy-champion-ken-jennings-experts-discuss/)\n",
    "    - [IBM's Watson Trivia Challenge](http://www.nytimes.com/interactive/2010/06/16/magazine/watson-trivia-game.html)\n",
    "    - [The AI Behind Watson](http://www.aaai.org/Magazine/Watson/watson.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These Higher Level Use Cases Stem From Foundational Concepts\n",
    "<b> Which we will go over today </b>\n",
    "\n",
    "\n",
    "- Text Vectorization: representing text into numbers\n",
    "- N-Gram: what is considered a \n",
    "- Stop Words:\n",
    "- Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Caveat:\n",
    "\n",
    "### NLP is Generaly Hard. Why?\n",
    "\n",
    "\n",
    "Natural language processing requires an understanding of the language and the world. <br>\n",
    "Several limitations of NLP are:\n",
    "\n",
    "- **Ambiguity**:\n",
    "    - Hospitals Are Sued by 7 Foot Doctors\n",
    "    - Juvenile Court to Try Shooting Defendant\n",
    "    - Local High School Dropouts Cut in Half\n",
    "- **Non-standard English:** text messages\n",
    "- **Idioms:** \"throw in the towel\"\n",
    "- **Newly coined words:** \"retweet\"\n",
    "- **Tricky entity names:** \"Where is A Bug's Life playing?\"\n",
    "- **World knowledge:** \"Mary and Sue are sisters\", \"Mary and Sue are mothers\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Although we can capture as much of the text's information through numbers, some of it get's lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Along:\n",
    "\n",
    "<b>Challenge: </b> <br>\n",
    "Can You Predict A Positive or Negative Yelp Review Based on the Text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'./data/yelp.csv'\n",
    "yelp = pd.read_csv(path)\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some NLP Terms: \n",
    "- **document**: one row of text (in this case one review)\n",
    "- **corpus**: a collection of documents (in this case all of the reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define X and y.\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the new DataFrame into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0      5  My wife took me here on my birthday for breakf...\n",
       "1      5  I have no idea why some people give bad review...\n",
       "3      5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4      5  General Manager Scott Petello is a good egg!!!...\n",
       "6      5  Drop what you're doing and drive here. After I..."
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The head of the original data\n",
    "yelp_best_worst[['stars', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is done in the same way as all other classification models. \n",
    "\n",
    "- First, the text is vectorized into a set of numeric features. \n",
    "- Then, a standard machine learning classifier is applied. \n",
    "- NLP libraries often include vectorizers and ML models that work particularly well with text.\n",
    "\n",
    "\n",
    "**Text classification is the task of predicting which category or topic a text sample is from.**\n",
    "\n",
    "We may want to identify:\n",
    "- Is an article a sports or business story?\n",
    "- Does an email have positive or negative sentiment?\n",
    "- Is the rating of a recipe 1, 2, 3, 4, or 5 stars?\n",
    "\n",
    "**Predictions are often made by using the words as features and the label as the target output.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Text Vectorization\n",
    "\n",
    "We will represent our text numerically using the <b>bag of words model.</b>\n",
    "\n",
    "It is called bag of words because the document's structure is lost — as if the words are all jumbled up in a bag.\n",
    "The first step to creating a bag-of-words model is to create a vocabulary of all possible words in the corpora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words means uses:\n",
    "- a vocabulary of known words\n",
    "- a measure of presense of the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DTM](images/nlp_viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DTM](images/DTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Scikit Learn to Vectorize Yelp Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6841    FILLY-B's!!!!!  only 8 reviews?? NINE now!!!\\n...\n",
       "1728    My husband and I absolutely LOVE this restaura...\n",
       "3853    We went today after lunch. I got my usual of l...\n",
       "671     Totally dissapointed.  I had purchased a coupo...\n",
       "4920    Costco Travel - My husband and I recently retu...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rows are documents, columns are terms (aka \"tokens\" or \"features\", individual words in this situation).\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '00a', '00am', '00pm', '01', '02', '03', '03342', '04', '05', '06', '07', '09', '0buxoc0crqjpvkezo3bqog', '0l', '10', '100', '1000', '1000x', '1001', '100th', '101', '102', '105', '1070', '108', '10am', '10ish', '10min', '10mins', '10minutes', '10pm', '10th', '10x', '11', '110', '1100', '111', '111th', '112', '115th', '118', '11a', '11am', '11p', '11pm', '12', '120', '128i']\n"
     ]
    }
   ],
   "source": [
    "# First 50 features\n",
    "print((vect.get_feature_names()[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yyyyy', 'z11', 'za', 'zabba', 'zach', 'zam', 'zanella', 'zankou', 'zappos', 'zatsiki', 'zen', 'zero', 'zest', 'zexperience', 'zha', 'zhou', 'zia', 'zihuatenejo', 'zilch', 'zin', 'zinburger', 'zinburgergeist', 'zinc', 'zinfandel', 'zing', 'zip', 'zipcar', 'zipper', 'zippers', 'zipps', 'ziti', 'zoe', 'zombi', 'zombies', 'zone', 'zones', 'zoning', 'zoo', 'zoyo', 'zucca', 'zucchini', 'zuchinni', 'zumba', 'zupa', 'zuzu', 'zwiebel', 'zzed', 'éclairs', 'école', 'ém']\n"
     ]
    }
   ],
   "source": [
    "# Last 50 features\n",
    "print((vect.get_feature_names()[-50:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16825"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Measure Of Presense\n",
    "In this case count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00a</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>03342</th>\n",
       "      <th>04</th>\n",
       "      <th>...</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuchinni</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zupa</th>\n",
       "      <th>zuzu</th>\n",
       "      <th>zwiebel</th>\n",
       "      <th>zzed</th>\n",
       "      <th>éclairs</th>\n",
       "      <th>école</th>\n",
       "      <th>ém</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 16825 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  00a  00am  00pm  01  02  03  03342  04 ...  zucchini  zuchinni  \\\n",
       "0   0    0    0     0     0   0   0   0      0   0 ...         0         0   \n",
       "\n",
       "   zumba  zupa  zuzu  zwiebel  zzed  éclairs  école  ém  \n",
       "0      0     0     0        0     0        0      0   0  \n",
       "\n",
       "[1 rows x 16825 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.DataFrame(X_train_dtm.todense()[21][-50:], columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectorizer Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Remove Words in Vocabulary That Are to Be Very Rare or Very Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.todense(), columns=vect.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.todense(), columns=vect.get_feature_names())['is'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.todense(), columns=vect.get_feature_names())['000'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We Can Eliminate These Very Common Words Using Count Vectorizer's Stop Words Hyper Parameter\n",
    "\n",
    "These extremely common words & non predictive words are called <b> Stop Words </b>\n",
    "    \n",
    "By removing them we save in performance costs, and since they are so frequent we lower their influence within the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'is' in vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16528)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.todense(), columns=vect.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Example Of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ie',\n",
       " 'over',\n",
       " 'where',\n",
       " 'eg',\n",
       " 'him',\n",
       " 'eight',\n",
       " 'nowhere',\n",
       " 'wherein',\n",
       " 'less',\n",
       " 'show',\n",
       " 'anyhow',\n",
       " 'six',\n",
       " 'ever',\n",
       " 'put',\n",
       " 'system',\n",
       " 'sincere',\n",
       " 'there',\n",
       " 'others',\n",
       " 'sixty',\n",
       " 'neither',\n",
       " 'serious',\n",
       " 're',\n",
       " 'very',\n",
       " 'latter',\n",
       " 'which',\n",
       " 'namely',\n",
       " 'whom',\n",
       " 'back',\n",
       " 'latterly',\n",
       " 'fifty',\n",
       " 'your',\n",
       " 'whether',\n",
       " 'often',\n",
       " 'in',\n",
       " 'becoming',\n",
       " 'we',\n",
       " 'along',\n",
       " 'un',\n",
       " 'sometimes',\n",
       " 'me',\n",
       " 'being',\n",
       " 'done',\n",
       " 'must',\n",
       " 'another',\n",
       " 'until',\n",
       " 'hers',\n",
       " 'else',\n",
       " 'inc',\n",
       " 'its',\n",
       " 'towards',\n",
       " 'five',\n",
       " 'down',\n",
       " 'his',\n",
       " 'name',\n",
       " 'meanwhile',\n",
       " 'both',\n",
       " 'above',\n",
       " 'off',\n",
       " 'himself',\n",
       " 'onto',\n",
       " 'beyond',\n",
       " 'several',\n",
       " 'toward',\n",
       " 'amount',\n",
       " 'move',\n",
       " 'am',\n",
       " 'elsewhere',\n",
       " 'sometime',\n",
       " 'ten',\n",
       " 'whole',\n",
       " 'become',\n",
       " 'anyone',\n",
       " 'besides',\n",
       " 'much',\n",
       " 'their',\n",
       " 'around',\n",
       " 'whose',\n",
       " 'mostly',\n",
       " 'should',\n",
       " 'to',\n",
       " 'mill',\n",
       " 'so',\n",
       " 'three',\n",
       " 'seem',\n",
       " 'least',\n",
       " 'before',\n",
       " 'again',\n",
       " 'will',\n",
       " 'can',\n",
       " 'co',\n",
       " 'get',\n",
       " 'each',\n",
       " 'than',\n",
       " 'her',\n",
       " 'up',\n",
       " 'everyone',\n",
       " 'how',\n",
       " 'nine',\n",
       " 'either',\n",
       " 'yourself',\n",
       " 'thereby',\n",
       " 'seems',\n",
       " 'bill',\n",
       " 'anything',\n",
       " 'what',\n",
       " 'seemed',\n",
       " 'could',\n",
       " 'give',\n",
       " 'thru',\n",
       " 'former',\n",
       " 'third',\n",
       " 'nor',\n",
       " 'because',\n",
       " 'they',\n",
       " 'do',\n",
       " 'why',\n",
       " 'yet',\n",
       " 'although',\n",
       " 'or',\n",
       " 'thick',\n",
       " 'find',\n",
       " 'are',\n",
       " 'nevertheless',\n",
       " 'too',\n",
       " 'thereupon',\n",
       " 'hereupon',\n",
       " 'detail',\n",
       " 'someone',\n",
       " 'never',\n",
       " 'except',\n",
       " 'thin',\n",
       " 'our',\n",
       " 'mine',\n",
       " 'while',\n",
       " 'may',\n",
       " 'every',\n",
       " 'go',\n",
       " 'my',\n",
       " 'across',\n",
       " 'describe',\n",
       " 'call',\n",
       " 'four',\n",
       " 'not',\n",
       " 'even',\n",
       " 'some',\n",
       " 'see',\n",
       " 'therein',\n",
       " 'together',\n",
       " 'whereafter',\n",
       " 'whenever',\n",
       " 'them',\n",
       " 'none',\n",
       " 'behind',\n",
       " 'by',\n",
       " 'con',\n",
       " 'same',\n",
       " 'further',\n",
       " 'anywhere',\n",
       " 'on',\n",
       " 'own',\n",
       " 'eleven',\n",
       " 'us',\n",
       " 'but',\n",
       " 'whither',\n",
       " 'take',\n",
       " 'indeed',\n",
       " 'as',\n",
       " 'it',\n",
       " 'yours',\n",
       " 'is',\n",
       " 'if',\n",
       " 'one',\n",
       " 'herself',\n",
       " 'somehow',\n",
       " 'few',\n",
       " 'thereafter',\n",
       " 'fill',\n",
       " 'perhaps',\n",
       " 'been',\n",
       " 'however',\n",
       " 'twenty',\n",
       " 'thus',\n",
       " 'all',\n",
       " 'alone',\n",
       " 'otherwise',\n",
       " 'everywhere',\n",
       " 'whatever',\n",
       " 'amoungst',\n",
       " 'about',\n",
       " 'this',\n",
       " 'nobody',\n",
       " 'couldnt',\n",
       " 'among',\n",
       " 'itself',\n",
       " 'whereas',\n",
       " 'most',\n",
       " 'found',\n",
       " 'hasnt',\n",
       " 'out',\n",
       " 'made',\n",
       " 'seeming',\n",
       " 'side',\n",
       " 'hereafter',\n",
       " 'many',\n",
       " 'when',\n",
       " 'without',\n",
       " 'cant',\n",
       " 'ourselves',\n",
       " 'rather',\n",
       " 'hundred',\n",
       " 'fifteen',\n",
       " 'hence',\n",
       " 'beside',\n",
       " 'now',\n",
       " 'then',\n",
       " 'had',\n",
       " 'through',\n",
       " 'therefore',\n",
       " 'beforehand',\n",
       " 'has',\n",
       " 'de',\n",
       " 'would',\n",
       " 'enough',\n",
       " 'other',\n",
       " 'front',\n",
       " 'were',\n",
       " 'against',\n",
       " 'she',\n",
       " 'noone',\n",
       " 'hereby',\n",
       " 'anyway',\n",
       " 'though',\n",
       " 'under',\n",
       " 'full',\n",
       " 'since',\n",
       " 'with',\n",
       " 'top',\n",
       " 'whereby',\n",
       " 'ours',\n",
       " 'no',\n",
       " 'nothing',\n",
       " 'i',\n",
       " 'always',\n",
       " 'last',\n",
       " 'into',\n",
       " 'fire',\n",
       " 'more',\n",
       " 'something',\n",
       " 'afterwards',\n",
       " 'well',\n",
       " 'interest',\n",
       " 'any',\n",
       " 'becomes',\n",
       " 'that',\n",
       " 'cannot',\n",
       " 'whence',\n",
       " 'here',\n",
       " 'these',\n",
       " 'might',\n",
       " 'those',\n",
       " 'became',\n",
       " 'myself',\n",
       " 'such',\n",
       " 'bottom',\n",
       " 'forty',\n",
       " 'almost',\n",
       " 'due',\n",
       " 'after',\n",
       " 'part',\n",
       " 'and',\n",
       " 'still',\n",
       " 'during',\n",
       " 'wherever',\n",
       " 'have',\n",
       " 'twelve',\n",
       " 'a',\n",
       " 'whoever',\n",
       " 'themselves',\n",
       " 'from',\n",
       " 'the',\n",
       " 'upon',\n",
       " 'of',\n",
       " 'per',\n",
       " 'at',\n",
       " 'also',\n",
       " 'via',\n",
       " 'below',\n",
       " 'herein',\n",
       " 'etc',\n",
       " 'everything',\n",
       " 'formerly',\n",
       " 'moreover',\n",
       " 'throughout',\n",
       " 'for',\n",
       " 'please',\n",
       " 'you',\n",
       " 'next',\n",
       " 'who',\n",
       " 'already',\n",
       " 'two',\n",
       " 'somewhere',\n",
       " 'an',\n",
       " 'empty',\n",
       " 'first',\n",
       " 'once',\n",
       " 'thence',\n",
       " 'cry',\n",
       " 'between',\n",
       " 'only',\n",
       " 'he',\n",
       " 'amongst',\n",
       " 'whereupon',\n",
       " 'ltd',\n",
       " 'within',\n",
       " 'was',\n",
       " 'yourselves',\n",
       " 'keep',\n",
       " 'be']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V1:\n",
    "\n",
    "- Count Vectorizer\n",
    "- Stop Words Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8874755381604696\n"
     ]
    }
   ],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# Use Naive Bayes to predict the star rating.\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "rf.fit(X_train_dtm, y_train)\n",
    "y_pred_class = rf.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy.\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.46      0.60       184\n",
      "           5       0.89      0.98      0.93       838\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1022\n",
      "   macro avg       0.87      0.72      0.77      1022\n",
      "weighted avg       0.88      0.89      0.87      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent 5 Stars: 0.8199608610567515\n",
      "Percent 1 Stars: 0.18003913894324852\n"
     ]
    }
   ],
   "source": [
    "# Calculate null accuracy.\n",
    "y_test_binary = np.where(y_test==5, 1, 0) # five stars become 1, one stars become 0\n",
    "print('Percent 5 Stars:', y_test_binary.mean())\n",
    "print('Percent 1 Stars:', 1 - y_test_binary.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'actual')"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(19680801)\n",
    "\n",
    "plt.scatter(y_test + 2*np.random.rand(len(y_test)), y_pred_class + 2*np.random.rand(len(y_pred_class)))\n",
    "plt.ylabel('predictions')\n",
    "plt.xlabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V2:\n",
    "\n",
    "- Count Vectorizer\n",
    "- Stop Words Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898238747553816\n"
     ]
    }
   ],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# Use Naive Bayes to predict the star rating.\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "rf.fit(X_train_dtm, y_train)\n",
    "y_pred_class = rf.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy.\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.54      0.66       184\n",
      "           5       0.91      0.98      0.94       838\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1022\n",
      "   macro avg       0.87      0.76      0.80      1022\n",
      "weighted avg       0.89      0.90      0.89      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Rare Words Should Also Be Removed\n",
    "\n",
    "\n",
    "Since they are so rare, their relationships with other words can be by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(stop_words='english', min_df=15) #Words have to appear more than 15 times in document\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 1718)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '20',\n",
       " '24',\n",
       " '25',\n",
       " '30',\n",
       " '40',\n",
       " '45',\n",
       " '50',\n",
       " '60',\n",
       " '90',\n",
       " '95',\n",
       " '99',\n",
       " 'able',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'accommodating',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'admit',\n",
       " 'adorable',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'ahead',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'alcohol',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'alright',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'ambiance',\n",
       " 'american',\n",
       " 'anniversary',\n",
       " 'annoying',\n",
       " 'answer',\n",
       " 'anymore',\n",
       " 'anyways',\n",
       " 'apart',\n",
       " 'apologized',\n",
       " 'apparently',\n",
       " 'appears',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'apple',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arizona',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'art',\n",
       " 'artichoke',\n",
       " 'asada',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asparagus',\n",
       " 'ass',\n",
       " 'asu',\n",
       " 'ate',\n",
       " 'atmosphere',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attitude',\n",
       " 'authentic',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'average',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'az',\n",
       " 'baby',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bags',\n",
       " 'baked',\n",
       " 'bakery',\n",
       " 'balance',\n",
       " 'banana',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'bars',\n",
       " 'bartender',\n",
       " 'bartenders',\n",
       " 'based',\n",
       " 'basically',\n",
       " 'basil',\n",
       " 'basis',\n",
       " 'bathroom',\n",
       " 'bbq',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'bed',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belly',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'beware',\n",
       " 'bianco',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bike',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bites',\n",
       " 'black',\n",
       " 'bland',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'body',\n",
       " 'bomb',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'books',\n",
       " 'booth',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bought',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brand',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'brick',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brisket',\n",
       " 'broke',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brunch',\n",
       " 'bruschetta',\n",
       " 'bucks',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'buffet',\n",
       " 'building',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'burger',\n",
       " 'burgers',\n",
       " 'burrito',\n",
       " 'burritos',\n",
       " 'business',\n",
       " 'businesses',\n",
       " 'busy',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'cakes',\n",
       " 'calamari',\n",
       " 'california',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'came',\n",
       " 'camelback',\n",
       " 'candy',\n",
       " 'car',\n",
       " 'caramel',\n",
       " 'card',\n",
       " 'care',\n",
       " 'cares',\n",
       " 'carne',\n",
       " 'carry',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashier',\n",
       " 'casual',\n",
       " 'catch',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'celebrate',\n",
       " 'center',\n",
       " 'central',\n",
       " 'cents',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chairs',\n",
       " 'chance',\n",
       " 'chandler',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charming',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checking',\n",
       " 'cheese',\n",
       " 'cheesecake',\n",
       " 'cheesy',\n",
       " 'chef',\n",
       " 'chefs',\n",
       " 'cherry',\n",
       " 'chewy',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chile',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chipotle',\n",
       " 'chips',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'chopped',\n",
       " 'chorizo',\n",
       " 'chose',\n",
       " 'chris',\n",
       " 'christmas',\n",
       " 'cinnamon',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classy',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'club',\n",
       " 'coast',\n",
       " 'cocktail',\n",
       " 'cocktails',\n",
       " 'coconut',\n",
       " 'coffee',\n",
       " 'coke',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'color',\n",
       " 'colors',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combo',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'comfy',\n",
       " 'coming',\n",
       " 'common',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'complain',\n",
       " 'complained',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'complimentary',\n",
       " 'concept',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'contact',\n",
       " 'continue',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'cook',\n",
       " 'cooked',\n",
       " 'cookie',\n",
       " 'cookies',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'corn',\n",
       " 'corner',\n",
       " 'correct',\n",
       " 'cost',\n",
       " 'couldn',\n",
       " 'counter',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'coupon',\n",
       " 'course',\n",
       " 'courses',\n",
       " 'courteous',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'coworkers',\n",
       " 'cozy',\n",
       " 'crab',\n",
       " 'crap',\n",
       " 'crave',\n",
       " 'craving',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'creamy',\n",
       " 'create',\n",
       " 'creative',\n",
       " 'credit',\n",
       " 'creme',\n",
       " 'crisp',\n",
       " 'crispy',\n",
       " 'crowd',\n",
       " 'crowded',\n",
       " 'crunchy',\n",
       " 'crust',\n",
       " 'cucumber',\n",
       " 'cuisine',\n",
       " 'culinary',\n",
       " 'cup',\n",
       " 'cupcakes',\n",
       " 'current',\n",
       " 'curry',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'damn',\n",
       " 'dark',\n",
       " 'darn',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'deals',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'decor',\n",
       " 'decorated',\n",
       " 'deep',\n",
       " 'definitely',\n",
       " 'deli',\n",
       " 'delicious',\n",
       " 'delight',\n",
       " 'delightful',\n",
       " 'delish',\n",
       " 'delivered',\n",
       " 'delivery',\n",
       " 'dentist',\n",
       " 'department',\n",
       " 'desert',\n",
       " 'desk',\n",
       " 'despite',\n",
       " 'dessert',\n",
       " 'desserts',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'die',\n",
       " 'diet',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dine',\n",
       " 'dined',\n",
       " 'diner',\n",
       " 'dining',\n",
       " 'dinner',\n",
       " 'dip',\n",
       " 'dipping',\n",
       " 'dirty',\n",
       " 'disappoint',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disappointment',\n",
       " 'discount',\n",
       " 'discovered',\n",
       " 'disgusting',\n",
       " 'dish',\n",
       " 'dishes',\n",
       " 'distance',\n",
       " 'dive',\n",
       " 'divine',\n",
       " 'doctor',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'doing',\n",
       " 'dollar',\n",
       " 'dollars',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'donuts',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'downtown',\n",
       " 'dozen',\n",
       " 'dr',\n",
       " 'dream',\n",
       " 'dress',\n",
       " 'dressing',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'drove',\n",
       " 'dry',\n",
       " 'duck',\n",
       " 'dude',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'eating',\n",
       " 'eats',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'egg',\n",
       " 'eggplant',\n",
       " 'eggs',\n",
       " 'employee',\n",
       " 'employees',\n",
       " 'enchiladas',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'entering',\n",
       " 'entire',\n",
       " 'entrance',\n",
       " 'entree',\n",
       " 'entrees',\n",
       " 'environment',\n",
       " 'equally',\n",
       " 'especially',\n",
       " 'espresso',\n",
       " 'establishment',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'events',\n",
       " 'everyday',\n",
       " 'everytime',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exceptional',\n",
       " 'excited',\n",
       " 'excuse',\n",
       " 'expect',\n",
       " 'expectations',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'experienced',\n",
       " 'experiences',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'express',\n",
       " 'extensive',\n",
       " 'extra',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'facility',\n",
       " 'fact',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fancy',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'fare',\n",
       " 'farm',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'fault',\n",
       " 'fav',\n",
       " 'favor',\n",
       " 'favorite',\n",
       " 'favorites',\n",
       " 'fee',\n",
       " 'feed',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'fiance',\n",
       " 'fig',\n",
       " 'figure',\n",
       " 'figured',\n",
       " 'filet',\n",
       " 'filled',\n",
       " 'filling',\n",
       " 'finally',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'fix',\n",
       " 'flat',\n",
       " 'flavor',\n",
       " 'flavored',\n",
       " 'flavorful',\n",
       " 'flavors',\n",
       " 'flight',\n",
       " 'floor',\n",
       " 'fly',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'food',\n",
       " 'foodie',\n",
       " 'foods',\n",
       " 'foot',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'forward',\n",
       " 'freaking',\n",
       " 'free',\n",
       " 'french',\n",
       " 'frequent',\n",
       " 'frequently',\n",
       " 'fresh',\n",
       " 'freshly',\n",
       " 'friday',\n",
       " 'fried',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'fries',\n",
       " 'frozen',\n",
       " 'fruit',\n",
       " 'fry',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'funky',\n",
       " 'funny',\n",
       " 'furniture',\n",
       " 'future',\n",
       " 'game',\n",
       " 'games',\n",
       " 'garden',\n",
       " 'garlic',\n",
       " 'gave',\n",
       " 'gelato',\n",
       " 'gem',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generous',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'glasses',\n",
       " 'gluten',\n",
       " 'goat',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'goodness',\n",
       " 'gorgeous',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'gotten',\n",
       " 'gourmet',\n",
       " 'grab',\n",
       " 'grand',\n",
       " 'gravy',\n",
       " 'greasy',\n",
       " 'great',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'greens',\n",
       " 'greeted',\n",
       " 'grew',\n",
       " 'grill',\n",
       " 'grilled',\n",
       " 'grocery',\n",
       " 'gross',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'groupon',\n",
       " 'growing',\n",
       " 'guacamole',\n",
       " 'guess',\n",
       " 'guest',\n",
       " 'guests',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'gyro',\n",
       " 'hadn',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'ham',\n",
       " 'hand',\n",
       " 'handed',\n",
       " 'hands',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hasn',\n",
       " 'hate',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'head',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heaven',\n",
       " 'heavy',\n",
       " 'heck',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'helpful',\n",
       " 'helping',\n",
       " 'hey',\n",
       " 'hidden',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highly',\n",
       " 'hint',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'hole',\n",
       " 'holy',\n",
       " 'home',\n",
       " 'homemade',\n",
       " 'honest',\n",
       " 'honestly',\n",
       " 'honey',\n",
       " 'hooked',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hoping',\n",
       " 'horrible',\n",
       " 'hostess',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'http',\n",
       " 'hubby',\n",
       " 'huge',\n",
       " 'hummus',\n",
       " 'hungry',\n",
       " 'husband',\n",
       " 'ice',\n",
       " 'iced',\n",
       " 'idea',\n",
       " 'ignored',\n",
       " 'imagine',\n",
       " 'immediately',\n",
       " 'important',\n",
       " 'importantly',\n",
       " 'impressed',\n",
       " 'impressive',\n",
       " 'include',\n",
       " 'included',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indian',\n",
       " 'inexpensive',\n",
       " 'information',\n",
       " 'informed',\n",
       " 'ingredient',\n",
       " 'ingredients',\n",
       " 'inside',\n",
       " 'instead',\n",
       " 'interesting',\n",
       " 'interior',\n",
       " 'intimate',\n",
       " 'introduced',\n",
       " 'inviting',\n",
       " 'isn',\n",
       " 'issue',\n",
       " 'issues',\n",
       " 'italian',\n",
       " 'item',\n",
       " 'items',\n",
       " 'japanese',\n",
       " 'jeans',\n",
       " 'job',\n",
       " 'joe',\n",
       " 'joint',\n",
       " 'joke',\n",
       " 'juice',\n",
       " 'juicy',\n",
       " 'just',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kidding',\n",
       " 'kids',\n",
       " 'killer',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'kinds',\n",
       " 'king',\n",
       " 'kitchen',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knowing',\n",
       " 'knowledge',\n",
       " 'knowledgeable',\n",
       " 'known',\n",
       " 'knows',\n",
       " 'la',\n",
       " 'lack',\n",
       " 'ladies',\n",
       " 'lady',\n",
       " 'laid',\n",
       " 'lamb',\n",
       " 'large',\n",
       " 'larger',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latte',\n",
       " 'learn',\n",
       " 'learned',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'left',\n",
       " 'leftovers',\n",
       " 'lemon',\n",
       " 'let',\n",
       " 'lettuce',\n",
       " 'level',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lighting',\n",
       " 'lights',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'likes',\n",
       " 'lime',\n",
       " 'limited',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'lit',\n",
       " 'literally',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lived',\n",
       " 'living',\n",
       " 'll',\n",
       " 'lobby',\n",
       " 'lobster',\n",
       " 'local',\n",
       " 'locally',\n",
       " 'located',\n",
       " 'location',\n",
       " 'locations',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'loud',\n",
       " 'lounge',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'loves',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'luck',\n",
       " 'luckily',\n",
       " 'lucky',\n",
       " 'lunch',\n",
       " 'mac',\n",
       " 'machine',\n",
       " 'main',\n",
       " 'major',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'mall',\n",
       " 'man',\n",
       " 'management',\n",
       " 'manager',\n",
       " 'mango',\n",
       " 'margarita',\n",
       " 'margaritas',\n",
       " 'market',\n",
       " 'martini',\n",
       " 'mashed',\n",
       " 'massage',\n",
       " 'match',\n",
       " 'matter',\n",
       " 'maybe',\n",
       " 'mayo',\n",
       " 'meal',\n",
       " 'meals',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meat',\n",
       " 'meats',\n",
       " 'mediocre',\n",
       " 'medium',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'melt',\n",
       " 'melted',\n",
       " 'member',\n",
       " 'members',\n",
       " 'memorable',\n",
       " 'men',\n",
       " 'mention',\n",
       " 'mentioned',\n",
       " 'menu',\n",
       " 'menus',\n",
       " 'mesa',\n",
       " 'mess',\n",
       " 'messy',\n",
       " 'met',\n",
       " 'metro',\n",
       " 'mexican',\n",
       " 'mexico',\n",
       " 'middle',\n",
       " 'mile',\n",
       " 'miles',\n",
       " 'milk',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mini',\n",
       " 'mint',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'missing',\n",
       " 'mistake',\n",
       " 'mix',\n",
       " 'mixed',\n",
       " 'modern',\n",
       " 'moist',\n",
       " 'mom',\n",
       " 'moment',\n",
       " 'monday',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'mood',\n",
       " 'morning',\n",
       " 'mother',\n",
       " 'mountain',\n",
       " 'mouth',\n",
       " 'moved',\n",
       " 'movie',\n",
       " 'moving',\n",
       " 'mozzarella',\n",
       " 'mr',\n",
       " 'multiple',\n",
       " 'mushroom',\n",
       " 'mushrooms',\n",
       " 'music',\n",
       " 'mustard',\n",
       " 'nachos',\n",
       " 'nail',\n",
       " 'nails',\n",
       " 'named',\n",
       " 'nasty',\n",
       " 'natural',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'nearly',\n",
       " 'neat',\n",
       " 'need',\n",
       " 'needed',\n",
       " 'needless',\n",
       " 'needs',\n",
       " 'negative',\n",
       " 'neighborhood',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'nicely',\n",
       " 'nicest',\n",
       " 'night',\n",
       " 'nights',\n",
       " 'non',\n",
       " 'noodle',\n",
       " 'noodles',\n",
       " 'normal',\n",
       " 'normally',\n",
       " 'north',\n",
       " 'notch',\n",
       " 'note',\n",
       " ...]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V3: \n",
    "\n",
    "- Count Vectorizer\n",
    "- Stop words\n",
    "- Minimum Occurance in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8904109589041096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(stop_words='english', min_df=15) #Words have to appear more than 15 times in document\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "rf.fit(X_train_dtm, y_train)\n",
    "y_pred_class = rf.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy.\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recap:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. We Can Add Combinations of Words via Ngrams\n",
    "\n",
    "For Example: <br>\n",
    "\n",
    "Data Scientist has additional meaning than data and scientist.\n",
    "\n",
    "N-grams are features which consist of N consecutive words. This is useful because using the bag-of-words model, treating `data scientist` as a single feature has more meaning than having two independent features `data` and `scientist`!\n",
    "\n",
    "Example:\n",
    "```\n",
    "my cat is awesome\n",
    "Unigrams (1-grams): 'my', 'cat', 'is', 'awesome'\n",
    "Bigrams (2-grams): 'my cat', 'cat is', 'is awesome'\n",
    "Trigrams (3-grams): 'my cat is', 'cat is awesome'\n",
    "4-grams: 'my cat is awesome'\n",
    "```\n",
    "\n",
    "- **ngram_range:** tuple (min_n, max_n)\n",
    "- The lower and upper boundary of the range of n-values for different n-grams to be extracted. All values of n such that min_n <= n <= max_n will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include 1-grams and 2-grams.\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 169847)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include 1-grams and 2-grams.\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zumba',\n",
       " 'zumba class',\n",
       " 'zumba or',\n",
       " 'zumba yogalates',\n",
       " 'zupa',\n",
       " 'zupa flavors',\n",
       " 'zuzu',\n",
       " 'zuzu in',\n",
       " 'zuzu is',\n",
       " 'zuzu the',\n",
       " 'zwiebel',\n",
       " 'zwiebel kräuter',\n",
       " 'zzed',\n",
       " 'zzed in',\n",
       " 'éclairs',\n",
       " 'éclairs napoleons',\n",
       " 'école',\n",
       " 'école lenôtre',\n",
       " 'ém',\n",
       " 'ém all']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: <br></b>\n",
    "Although we sometimes add important new features that have meaning such as `data scientist`, many of the new features will just be noise. So, particularly if we do not have much data, adding n-grams can actually decrease model performance. This is because if each n-gram is only present once or twice in the training set, we are effectively adding mostly noisy features to the mix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V4: \n",
    "\n",
    "- Count Vectorizer\n",
    "- Stop words\n",
    "- Minimum Occurance in DataFrame\n",
    "- Include Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8933463796477495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use default options for CountVectorizer.\n",
    "vect = CountVectorizer(stop_words='english', \n",
    "                       min_df=15,\n",
    "                      ngram_range=(1, 2)) #Words have to appear more than 15 times in document\n",
    "\n",
    "# Create document-term matrices.\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "rf.fit(X_train_dtm, y_train)\n",
    "y_pred_class = rf.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy.\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We Can Also Limit the Max Number Of Features Available\n",
    "\n",
    "It only limits the most frequently occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove English stop words and only keep 100 features.\n",
    "vect = CountVectorizer(stop_words='english', \n",
    "                       ngram_range=(1,2),\n",
    "                       max_features=100)\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 100)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V5: \n",
    "\n",
    "- Count Vectorizer\n",
    "- Stop words\n",
    "- Minimum Occurance in DataFrame\n",
    "- Include Bi-grams\n",
    "- Limit Number Of Words to 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_test(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print(('Features: ', X_train_dtm.shape[1]))\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    nb = RandomForestClassifier()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    print(('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 3000)\n",
      "('Accuracy: ', 0.8962818003913894)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', \n",
    "                       ngram_range=(1,2),\n",
    "                       max_features=3000)\n",
    "\n",
    "# Create document-term matrices.\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with all other models, more features does not mean a better model. So, we must tune our feature generator to remove features whose predictive capability is none or very low.\n",
    "\n",
    "In this case, we have increased included by grams and capped the number of features to 1,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 3000)\n",
      "('Accuracy: ', 0.8992172211350293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english',\n",
    "                       max_features=3000)\n",
    "\n",
    "# Create document-term matrices.\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Combining Tenses of The Same Word\n",
    "\n",
    "We want to include words that have the same meaning but have different tenses.\n",
    "\n",
    "Running, ran, run -> Run\n",
    "\n",
    "Chairs, Chair -> Chair\n",
    "\n",
    "### We Do This Via: Stemming and Lemmatization\n",
    "\n",
    "<b> i. Stemming is a crude process of removing common endings from sentences, such as \"s\", \"es\", \"ly\", \"ing\", and \"ed\". </b>\n",
    "\n",
    "- **What:** Reduce a word to its base/stem/root form.\n",
    "- **Why:** This intelligently reduces the number of features by grouping together (hopefully) related words.\n",
    "- **Notes:**\n",
    "    - Stemming uses a simple and fast rule-based approach.\n",
    "    - Stemmed words are usually not shown to users (used for analysis/indexing).\n",
    "    - Some search engines treat words with the same stem as synonyms.\n",
    "    \n",
    "    \n",
    "<b> ii. Lemmatization is a more refined process that uses specific language and grammar rules to derive the root of a word. </b>  \n",
    "\n",
    "This is useful for words that do not share an obvious root such as \"better\" and \"best\".\n",
    "\n",
    "- **What:** Lemmatization derives the canonical form (\"lemma\") of a word.\n",
    "- **Why:** It can be better than stemming.\n",
    "- **Notes:** Uses a dictionary-based approach (slower than stemming)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application With Text Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = TextBlob(yelp_best_worst.text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22977272727272727"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'have', 'no', 'idea', 'why', 'some', 'people', 'give', 'bad', 'reviews', 'about', 'this', 'place', 'It', 'goes', 'to', 'show', 'you', 'you', 'can', 'please', 'everyone', 'They', 'are', 'probably', 'griping', 'about', 'something', 'that', 'their', 'own', 'fault', 'there', 'are', 'many', 'people', 'like', 'that', 'In', 'any', 'case', 'my', 'friend', 'and', 'I', 'arrived', 'at', 'about', '5:50', 'PM', 'this', 'past', 'Sunday', 'It', 'was', 'pretty', 'crowded', 'more', 'than', 'I', 'thought', 'for', 'a', 'Sunday', 'evening', 'and', 'thought', 'we', 'would', 'have', 'to', 'wait', 'forever', 'to', 'get', 'a', 'seat', 'but', 'they', 'said', 'we', \"'ll\", 'be', 'seated', 'when', 'the', 'girl', 'comes', 'back', 'from', 'seating', 'someone', 'else', 'We', 'were', 'seated', 'at', '5:52', 'and', 'the', 'waiter', 'came', 'and', 'got', 'our', 'drink', 'orders', 'Everyone', 'was', 'very', 'pleasant', 'from', 'the', 'host', 'that', 'seated', 'us', 'to', 'the', 'waiter', 'to', 'the', 'server', 'The', 'prices', 'were', 'very', 'good', 'as', 'well', 'We', 'placed', 'our', 'orders', 'once', 'we', 'decided', 'what', 'we', 'wanted', 'at', '6:02', 'We', 'shared', 'the', 'baked', 'spaghetti', 'calzone', 'and', 'the', 'small', 'Here', \"'s\", 'The', 'Beef', 'pizza', 'so', 'we', 'can', 'both', 'try', 'them', 'The', 'calzone', 'was', 'huge', 'and', 'we', 'got', 'the', 'smallest', 'one', 'personal', 'and', 'got', 'the', 'small', '11', 'pizza', 'Both', 'were', 'awesome', 'My', 'friend', 'liked', 'the', 'pizza', 'better', 'and', 'I', 'liked', 'the', 'calzone', 'better', 'The', 'calzone', 'does', 'have', 'a', 'sweetish', 'sauce', 'but', 'that', \"'s\", 'how', 'I', 'like', 'my', 'sauce', 'We', 'had', 'to', 'box', 'part', 'of', 'the', 'pizza', 'to', 'take', 'it', 'home', 'and', 'we', 'were', 'out', 'the', 'door', 'by', '6:42', 'So', 'everything', 'was', 'great', 'and', 'not', 'like', 'these', 'bad', 'reviewers', 'That', 'goes', 'to', 'show', 'you', 'that', 'you', 'have', 'to', 'try', 'these', 'things', 'yourself', 'because', 'all', 'these', 'bad', 'reviewers', 'have', 'some', 'serious', 'issues'])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I have no idea why some people give bad reviews about this place.\"),\n",
       " Sentence(\"It goes to show you, you can please everyone.\"),\n",
       " Sentence(\"They are probably griping about something that their own fault...there are many people like that.\"),\n",
       " Sentence(\"In any case, my friend and I arrived at about 5:50 PM this past Sunday.\"),\n",
       " Sentence(\"It was pretty crowded, more than I thought for a Sunday evening and thought we would have to wait forever to get a seat but they said we'll be seated when the girl comes back from seating someone else.\"),\n",
       " Sentence(\"We were seated at 5:52 and the waiter came and got our drink orders.\"),\n",
       " Sentence(\"Everyone was very pleasant from the host that seated us to the waiter to the server.\"),\n",
       " Sentence(\"The prices were very good as well.\"),\n",
       " Sentence(\"We placed our orders once we decided what we wanted at 6:02.\"),\n",
       " Sentence(\"We shared the baked spaghetti calzone and the small \"Here's The Beef\" pizza so we can both try them.\"),\n",
       " Sentence(\"The calzone was huge and we got the smallest one (personal) and got the small 11\" pizza.\"),\n",
       " Sentence(\"Both were awesome!\"),\n",
       " Sentence(\"My friend liked the pizza better and I liked the calzone better.\"),\n",
       " Sentence(\"The calzone does have a sweetish sauce but that's how I like my sauce!\"),\n",
       " Sentence(\"We had to box part of the pizza to take it home and we were out the door by 6:42.\"),\n",
       " Sentence(\"So, everything was great and not like these bad reviewers.\"),\n",
       " Sentence(\"That goes to show you that  you have to try these things yourself because all these bad reviewers have some serious issues.\")]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'have', 'no', 'idea', 'why', 'some', 'people', 'give', 'bad', 'reviews', 'about', 'this', 'place', 'It', 'goes', 'to', 'show', 'you', 'you', 'can', 'please', 'everyone', 'They', 'are', 'probably', 'griping', 'about', 'something', 'that', 'their', 'own', 'fault', 'there', 'are', 'many', 'people', 'like', 'that', 'In', 'any', 'case', 'my', 'friend', 'and', 'I', 'arrived', 'at', 'about', '5:50', 'PM', 'this', 'past', 'Sunday', 'It', 'was', 'pretty', 'crowded', 'more', 'than', 'I', 'thought', 'for', 'a', 'Sunday', 'evening', 'and', 'thought', 'we', 'would', 'have', 'to', 'wait', 'forever', 'to', 'get', 'a', 'seat', 'but', 'they', 'said', 'we', \"'ll\", 'be', 'seated', 'when', 'the', 'girl', 'comes', 'back', 'from', 'seating', 'someone', 'else', 'We', 'were', 'seated', 'at', '5:52', 'and', 'the', 'waiter', 'came', 'and', 'got', 'our', 'drink', 'orders', 'Everyone', 'was', 'very', 'pleasant', 'from', 'the', 'host', 'that', 'seated', 'us', 'to', 'the', 'waiter', 'to', 'the', 'server', 'The', 'prices', 'were', 'very', 'good', 'as', 'well', 'We', 'placed', 'our', 'orders', 'once', 'we', 'decided', 'what', 'we', 'wanted', 'at', '6:02', 'We', 'shared', 'the', 'baked', 'spaghetti', 'calzone', 'and', 'the', 'small', 'Here', \"'s\", 'The', 'Beef', 'pizza', 'so', 'we', 'can', 'both', 'try', 'them', 'The', 'calzone', 'was', 'huge', 'and', 'we', 'got', 'the', 'smallest', 'one', 'personal', 'and', 'got', 'the', 'small', '11', 'pizza', 'Both', 'were', 'awesome', 'My', 'friend', 'liked', 'the', 'pizza', 'better', 'and', 'I', 'liked', 'the', 'calzone', 'better', 'The', 'calzone', 'does', 'have', 'a', 'sweetish', 'sauce', 'but', 'that', \"'s\", 'how', 'I', 'like', 'my', 'sauce', 'We', 'had', 'to', 'box', 'part', 'of', 'the', 'pizza', 'to', 'take', 'it', 'home', 'and', 'we', 'were', 'out', 'the', 'door', 'by', '6:42', 'So', 'everything', 'was', 'great', 'and', 'not', 'like', 'these', 'bad', 'reviewers', 'That', 'goes', 'to', 'show', 'you', 'that', 'you', 'have', 'to', 'try', 'these', 'things', 'yourself', 'because', 'all', 'these', 'bad', 'reviewers', 'have', 'some', 'serious', 'issues'])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'no', 'idea', 'whi', 'some', 'peopl', 'give', 'bad', 'review', 'about', 'this', 'place', 'it', 'goe', 'to', 'show', 'you', 'you', 'can', 'pleas', 'everyon', 'they', 'are', 'probabl', 'gripe', 'about', 'someth', 'that', 'their', 'own', 'fault', 'there', 'are', 'mani', 'peopl', 'like', 'that', 'in', 'ani', 'case', 'my', 'friend', 'and', 'i', 'arriv', 'at', 'about', '5:50', 'pm', 'this', 'past', 'sunday', 'it', 'was', 'pretti', 'crowd', 'more', 'than', 'i', 'thought', 'for', 'a', 'sunday', 'even', 'and', 'thought', 'we', 'would', 'have', 'to', 'wait', 'forev', 'to', 'get', 'a', 'seat', 'but', 'they', 'said', 'we', 'll', 'be', 'seat', 'when', 'the', 'girl', 'come', 'back', 'from', 'seat', 'someon', 'els', 'we', 'were', 'seat', 'at', '5:52', 'and', 'the', 'waiter', 'came', 'and', 'got', 'our', 'drink', 'order', 'everyon', 'was', 'veri', 'pleasant', 'from', 'the', 'host', 'that', 'seat', 'us', 'to', 'the', 'waiter', 'to', 'the', 'server', 'the', 'price', 'were', 'veri', 'good', 'as', 'well', 'we', 'place', 'our', 'order', 'onc', 'we', 'decid', 'what', 'we', 'want', 'at', '6:02', 'we', 'share', 'the', 'bake', 'spaghetti', 'calzon', 'and', 'the', 'small', 'here', \"'s\", 'the', 'beef', 'pizza', 'so', 'we', 'can', 'both', 'tri', 'them', 'the', 'calzon', 'was', 'huge', 'and', 'we', 'got', 'the', 'smallest', 'one', 'person', 'and', 'got', 'the', 'small', '11', 'pizza', 'both', 'were', 'awesom', 'my', 'friend', 'like', 'the', 'pizza', 'better', 'and', 'i', 'like', 'the', 'calzon', 'better', 'the', 'calzon', 'doe', 'have', 'a', 'sweetish', 'sauc', 'but', 'that', \"'s\", 'how', 'i', 'like', 'my', 'sauc', 'we', 'had', 'to', 'box', 'part', 'of', 'the', 'pizza', 'to', 'take', 'it', 'home', 'and', 'we', 'were', 'out', 'the', 'door', 'by', '6:42', 'so', 'everyth', 'was', 'great', 'and', 'not', 'like', 'these', 'bad', 'review', 'that', 'goe', 'to', 'show', 'you', 'that', 'you', 'have', 'to', 'tri', 'these', 'thing', 'yourself', 'becaus', 'all', 'these', 'bad', 'review', 'have', 'some', 'serious', 'issu']\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Stem each word.\n",
    "print([stemmer.stem(word) for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chair'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('chairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ran'"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('ran')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'have', 'no', 'idea', 'why', 'some', 'people', 'give', 'bad', 'reviews', 'about', 'this', 'place', 'It', 'goes', 'to', 'show', 'you', 'you', 'can', 'please', 'everyone', 'They', 'are', 'probably', 'griping', 'about', 'something', 'that', 'their', 'own', 'fault', 'there', 'are', 'many', 'people', 'like', 'that', 'In', 'any', 'case', 'my', 'friend', 'and', 'I', 'arrived', 'at', 'about', '5:50', 'PM', 'this', 'past', 'Sunday', 'It', 'was', 'pretty', 'crowded', 'more', 'than', 'I', 'thought', 'for', 'a', 'Sunday', 'evening', 'and', 'thought', 'we', 'would', 'have', 'to', 'wait', 'forever', 'to', 'get', 'a', 'seat', 'but', 'they', 'said', 'we', \"'ll\", 'be', 'seated', 'when', 'the', 'girl', 'comes', 'back', 'from', 'seating', 'someone', 'else', 'We', 'were', 'seated', 'at', '5:52', 'and', 'the', 'waiter', 'came', 'and', 'got', 'our', 'drink', 'orders', 'Everyone', 'was', 'very', 'pleasant', 'from', 'the', 'host', 'that', 'seated', 'us', 'to', 'the', 'waiter', 'to', 'the', 'server', 'The', 'prices', 'were', 'very', 'good', 'as', 'well', 'We', 'placed', 'our', 'orders', 'once', 'we', 'decided', 'what', 'we', 'wanted', 'at', '6:02', 'We', 'shared', 'the', 'baked', 'spaghetti', 'calzone', 'and', 'the', 'small', 'Here', \"'s\", 'The', 'Beef', 'pizza', 'so', 'we', 'can', 'both', 'try', 'them', 'The', 'calzone', 'was', 'huge', 'and', 'we', 'got', 'the', 'smallest', 'one', 'personal', 'and', 'got', 'the', 'small', '11', 'pizza', 'Both', 'were', 'awesome', 'My', 'friend', 'liked', 'the', 'pizza', 'better', 'and', 'I', 'liked', 'the', 'calzone', 'better', 'The', 'calzone', 'does', 'have', 'a', 'sweetish', 'sauce', 'but', 'that', \"'s\", 'how', 'I', 'like', 'my', 'sauce', 'We', 'had', 'to', 'box', 'part', 'of', 'the', 'pizza', 'to', 'take', 'it', 'home', 'and', 'we', 'were', 'out', 'the', 'door', 'by', '6:42', 'So', 'everything', 'was', 'great', 'and', 'not', 'like', 'these', 'bad', 'reviewers', 'That', 'goes', 'to', 'show', 'you', 'that', 'you', 'have', 'to', 'try', 'these', 'things', 'yourself', 'because', 'all', 'these', 'bad', 'reviewers', 'have', 'some', 'serious', 'issues'])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'no', 'idea', 'why', 'some', 'people', 'give', 'bad', 'review', 'about', 'this', 'place', 'It', 'go', 'to', 'show', 'you', 'you', 'can', 'please', 'everyone', 'They', 'are', 'probably', 'griping', 'about', 'something', 'that', 'their', 'own', 'fault', 'there', 'are', 'many', 'people', 'like', 'that', 'In', 'any', 'case', 'my', 'friend', 'and', 'I', 'arrived', 'at', 'about', '5:50', 'PM', 'this', 'past', 'Sunday', 'It', 'wa', 'pretty', 'crowded', 'more', 'than', 'I', 'thought', 'for', 'a', 'Sunday', 'evening', 'and', 'thought', 'we', 'would', 'have', 'to', 'wait', 'forever', 'to', 'get', 'a', 'seat', 'but', 'they', 'said', 'we', \"'ll\", 'be', 'seated', 'when', 'the', 'girl', 'come', 'back', 'from', 'seating', 'someone', 'else', 'We', 'were', 'seated', 'at', '5:52', 'and', 'the', 'waiter', 'came', 'and', 'got', 'our', 'drink', 'order', 'Everyone', 'wa', 'very', 'pleasant', 'from', 'the', 'host', 'that', 'seated', 'u', 'to', 'the', 'waiter', 'to', 'the', 'server', 'The', 'price', 'were', 'very', 'good', 'a', 'well', 'We', 'placed', 'our', 'order', 'once', 'we', 'decided', 'what', 'we', 'wanted', 'at', '6:02', 'We', 'shared', 'the', 'baked', 'spaghetti', 'calzone', 'and', 'the', 'small', 'Here', \"'s\", 'The', 'Beef', 'pizza', 'so', 'we', 'can', 'both', 'try', 'them', 'The', 'calzone', 'wa', 'huge', 'and', 'we', 'got', 'the', 'smallest', 'one', 'personal', 'and', 'got', 'the', 'small', '11', 'pizza', 'Both', 'were', 'awesome', 'My', 'friend', 'liked', 'the', 'pizza', 'better', 'and', 'I', 'liked', 'the', 'calzone', 'better', 'The', 'calzone', 'doe', 'have', 'a', 'sweetish', 'sauce', 'but', 'that', \"'s\", 'how', 'I', 'like', 'my', 'sauce', 'We', 'had', 'to', 'box', 'part', 'of', 'the', 'pizza', 'to', 'take', 'it', 'home', 'and', 'we', 'were', 'out', 'the', 'door', 'by', '6:42', 'So', 'everything', 'wa', 'great', 'and', 'not', 'like', 'these', 'bad', 'reviewer', 'That', 'go', 'to', 'show', 'you', 'that', 'you', 'have', 'to', 'try', 'these', 'thing', 'yourself', 'because', 'all', 'these', 'bad', 'reviewer', 'have', 'some', 'serious', 'issue']\n"
     ]
    }
   ],
   "source": [
    "print([word.lemmatize() for word in review.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('ran').words[0].lemmatize(pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like'"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('liked').words[0].lemmatize(pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('was').words[0].lemmatize(pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('were').words[0].lemmatize(pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Lemmatization and Stemming Examples**\n",
    "\n",
    "|Lemmatization|Stemming|\n",
    "|-------------|---------|\n",
    "|shouted → shout|badly → bad|\n",
    "|was → be|computing → comput|\n",
    "|were → be|computed → comput|\n",
    "|wiping → wipe|wiped → wip|\n",
    "|hidden → hide|wiping → wip|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V6\n",
    "\n",
    "\n",
    "- Count Vectorizer\n",
    "- Stop words\n",
    "- Minimum Occurance in DataFrame\n",
    "- Include Bi-grams\n",
    "- Limit Number Of Words to 400\n",
    "- Lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 16444)\n",
      "('Accuracy: ', 0.8610567514677103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_lemmas)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 16444)\n",
      "('Accuracy: ', 0.8659491193737769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_lemmas,\n",
    "                        stop_words='english')\n",
    "\n",
    "# Create document-term matrices.\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Term Frequency–Inverse Document Frequency (TF–IDF)\n",
    "\n",
    "Currently the measure of presense of the words has been the counts of words.\n",
    "\n",
    "But what if a word is very common among all the documents?\n",
    "\n",
    "If we were to use use NYT data during the election, Trump would appear very frequently.\n",
    "\n",
    "Two possible solutions:\n",
    "- Add Trump as a stop word\n",
    "- Calculate the difference between a word's occurance between a document to the corpus\n",
    "\n",
    "\n",
    "- **What:** Term frequency–inverse document frequency (TF–IDF) computes the \"relative frequency\" with which a word appears in a document, compared to its frequency across all documents.\n",
    "- **Why:** It's more useful than \"term frequency\" for identifying \"important\" words in each document (high frequency in that document, low frequency in other documents).\n",
    "- **Notes:** It's used for search-engine scoring, text summarization, and document clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Occurance Across Documents\n",
    "\n",
    "vect = CountVectorizer()\n",
    "tf = pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    1     3   2       2        1    1"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Occurances between the corpus (all documents)\n",
    "vect = CountVectorizer()\n",
    "df = vect.fit_transform(simple_train).toarray().sum(axis=0)\n",
    "pd.DataFrame(df.reshape(1, 6), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit_transform(simple_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab      call   me  please  tonight  you\n",
       "0  0.0  0.333333  0.0     0.0      1.0  1.0\n",
       "1  1.0  0.333333  0.5     0.0      0.0  0.0\n",
       "2  0.0  0.333333  0.5     1.0      0.0  0.0"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term frequency–inverse document frequency (simple version)\n",
    "tf/df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if a word is very high occuring like \"call\" the highest value it can get per row is .33. <br>\n",
    "Compared to please which get has the highest value of 1 for the third document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.342620</td>\n",
       "      <td>0.901008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cab      call        me    please   tonight       you\n",
       "0  0.000000  0.385372  0.000000  0.000000  0.652491  0.652491\n",
       "1  0.720333  0.425441  0.547832  0.000000  0.000000  0.000000\n",
       "2  0.000000  0.266075  0.342620  0.901008  0.000000  0.000000"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DTM](images/tf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term frequency:\n",
    "- Numerator: occurances of term in document\n",
    "- Denomenator: total words in document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DTM](images/idf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Document Frequency:\n",
    "- log\n",
    "- Numerator: N is number of documents\n",
    "- Denomenator: number of documents containing the term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DTM](images/tfidf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.652491</td>\n",
       "      <td>0.652491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720333</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.547832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266075</td>\n",
       "      <td>0.342620</td>\n",
       "      <td>0.901008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cab      call        me    please   tonight       you\n",
       "0  0.000000  0.385372  0.000000  0.000000  0.652491  0.652491\n",
       "1  0.720333  0.425441  0.547832  0.000000  0.000000  0.000000\n",
       "2  0.000000  0.266075  0.342620  0.901008  0.000000  0.000000"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "pd.DataFrame(vect.fit_transform(simple_train).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification V7\n",
    "\n",
    "\n",
    "- TFIDF Vectorizer\n",
    "- Stop words\n",
    "- Lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Features: ', 16444)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy: ', 0.8767123287671232)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english',\n",
    "                      analyzer=split_into_lemmas)\n",
    "\n",
    "# Fit transform Yelp data.\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would it do worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Understanding how positive or negative a review is. There are many ways in practice to compute a sentiment value. For example:\n",
    "\n",
    "- Have a list of \"positive\" words and a list of \"negative\" words and count how many occur in a document. \n",
    "- Train a classifier given many examples of \"positive\" documents and \"negative\" documents. \n",
    "    - Note that this technique is often just an automated way to derive the first (e.g., using bag-of-words with logistic regression, a coefficient is assigned to each word!).\n",
    "\n",
    "For the most accurate sentiment analysis, you will want to train a custom sentiment model based on documents that are particular to your application. Generic models (such as the one we are about to use!) often do not work as well as hoped.\n",
    "\n",
    "As we will do below, always make sure you double-check that the algorithm is working by manually verifying that scores correctly correspond to positive/negative reviews! Otherwise, you may be using numbers that are not accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no idea why some people give bad reviews about this place. It goes to show you, you can please everyone. They are probably griping about something that their own fault...there are many people like that.\n",
      "\n",
      "In any case, my friend and I arrived at about 5:50 PM this past Sunday. It was pretty crowded, more than I thought for a Sunday evening and thought we would have to wait forever to get a seat but they said we'll be seated when the girl comes back from seating someone else. We were seated at 5:52 and the waiter came and got our drink orders. Everyone was very pleasant from the host that seated us to the waiter to the server. The prices were very good as well. We placed our orders once we decided what we wanted at 6:02. We shared the baked spaghetti calzone and the small \"Here's The Beef\" pizza so we can both try them. The calzone was huge and we got the smallest one (personal) and got the small 11\" pizza. Both were awesome! My friend liked the pizza better and I liked the calzone better. The calzone does have a sweetish sauce but that's how I like my sauce!\n",
      "\n",
      "We had to box part of the pizza to take it home and we were out the door by 6:42. So, everything was great and not like these bad reviewers. That goes to show you that  you have to try these things yourself because all these bad reviewers have some serious issues.\n"
     ]
    }
   ],
   "source": [
    "print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22977272727272727"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polarity ranges from -1 (most negative) to 1 (most positive).\n",
    "review.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('this is the best restaurant I have ever been to').sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('this is the worst restaurant I have ever been to').sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Mistake\n",
    "TextBlob('this is not the best restaurant I have ever been to').sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding Polarity as A New Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  length  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0     889  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding the apply method\n",
    "yelp['length'] = yelp.text.apply(len)\n",
    "yelp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "    #return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['sentiment'] = yelp.text.apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bb0e579e8>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yelp.boxplot(column='sentiment', by='stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254    Our server Gary was awesome. Food was amazing....\n",
       "347    3 syllables for this place. \\nA-MAZ-ING!\\n\\nTh...\n",
       "420                                    LOVE the food!!!!\n",
       "459    Love it!!! Wish we still lived in Arizona as C...\n",
       "679                                     Excellent burger\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp[yelp.sentiment == 1].text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773     This was absolutely horrible. I got the suprem...\n",
       "1517                  Nasty workers and over priced trash\n",
       "3266    Absolutely awful... these guys have NO idea wh...\n",
       "4766                                       Very bad food!\n",
       "5812        I wouldn't send my worst enemy to this place.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp[yelp.sentiment == -1].text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RIP AZ Coffee Connection.  :(  I stopped by two days ago unaware that they had closed.  I am severely bummed.  This place is irreplaceable!  Damn you, Starbucks and McDonalds!'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative sentiment in a 5-star review\n",
    "yelp[(yelp.stars == 5) & (yelp.sentiment < -0.3)].iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you like the stuck up Scottsdale vibe this is a good place for you. The food isn't impressive. Nice outdoor seating.\""
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive sentiment in a 1-star review\n",
    "yelp[(yelp.stars == 1) & (yelp.sentiment > 0.5)].iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding The New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame that only contains the 5-star and 1-star reviews.\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['text', 'sentiment', 'cool', 'useful', 'funny']\n",
    "X = yelp_best_worst[feature_cols]\n",
    "y = yelp_best_worst.stars\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064, 16825)\n",
      "(1022, 16825)\n"
     ]
    }
   ],
   "source": [
    "# Use CountVectorizer with text column only.\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train.text)\n",
    "X_test_dtm = vect.transform(X_test.text)\n",
    "print((X_train_dtm.shape))\n",
    "print((X_test_dtm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 4)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of other four feature columns\n",
    "X_train.drop('text', axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 4)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast other feature columns to float and convert to a sparse matrix.\n",
    "extra = sp.sparse.csr_matrix(X_train.drop('text', axis=1).astype(float))\n",
    "extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16829)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine sparse matrices.\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "X_train_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 16829)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat for testing set.\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('text', axis=1).astype(float))\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))\n",
    "X_test_dtm_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9256360078277887\n"
     ]
    }
   ],
   "source": [
    "# Use logistic regression with text column only.\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9373776908023483\n"
     ]
    }
   ],
   "source": [
    "# Use logistic regression with all features.\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm_extra)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Fun TextBlob Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"15 minutes late\")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spelling correction\n",
    "TextBlob('15 minuets late').correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('part', 0.9929478138222849), ('parrot', 0.007052186177715092)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spellcheck\n",
    "Word('parot').spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tip laterally',\n",
       " 'enclose with a bank',\n",
       " 'do business with a bank or keep an account at a bank',\n",
       " 'act as the banker in a game or in gambling',\n",
       " 'be in the banking business',\n",
       " 'put into a bank account',\n",
       " 'cover with ashes so to control the rate of burning',\n",
       " 'have confidence or faith in']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definitions\n",
    "Word('bank').define('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Language identification\n",
    "TextBlob('Hola amigos').detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bayes\"></a>\n",
    "\n",
    "## Appendix: Intro to Naive Bayes and Text Classification\n",
    "\n",
    "\n",
    "Earlier we experimented with text classification using a Naive Bayes model. What exactly are Naive Bayes classifiers? \n",
    "\n",
    "**What is Bayes?**  \n",
    "Bayes, or Bayes' Theorem, is a different way to assess probability. It considers prior information in order to more accurately assess the situation.\n",
    "\n",
    "**Example:** You are playing roulette.\n",
    "\n",
    "As you approach the table, you see that the last number the ball landed on was Red-3. With a frequentist mindset, you know that the ball is just as likely to land on Red-3 again given that every slot on the wheel has an equal opportunity of 1 in 37.\n",
    "\n",
    "Given that you started believing that the ball can land in each slot with an equal likelihood _and_ that you have only seen one throw previously, you rationally believe that there would be no difference between picking Red a second time now or picking Black -- ideally they would happen with the same likelihood!\n",
    "\n",
    "However, as you sit and watch the roulette table, you begin to notice something strange. The ball is _always_ landing on red. Every single time the ball is thrown, it lands in a red slot. Even though your past beliefs stated that red and black were equally likely, every time it lands in red, you change those beliefs a little more towards a biased roulette table. \n",
    "\n",
    "This is what Bayes is all about — adjusting probabilities as more data is gathered!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the equation for Bayes.  \n",
    "\n",
    "$$P(A \\ | \\ B) = \\frac {P(B \\ | \\ A) \\times P(A)} {P(B)}$$\n",
    "\n",
    "- **$P(A \\ | \\ B)$** : Probability of `Event A` occurring given `Event B` has occurred.\n",
    "- **$P(B \\ | \\ A)$** : Probability of `Event B` occurring given `Event A` has occurred.\n",
    "- **$P(A)$** : Probability of `Event A` occurring.\n",
    "- **$P(B)$** : Probability of `Event B` occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion\n",
    "\n",
    "- NLP is a gigantic field.\n",
    "- Understanding the basics broadens the types of data you can work with.\n",
    "- Simple techniques go a long way.\n",
    "- Use scikit-learn for NLP whenever possible.\n",
    "\n",
    "While we used SKLearn and TextBlob today, another popular python NLP library is [Spacy](https://spacy.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: Predict Whether A Project Will Get Funded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateparse(date_string):\n",
    "    return datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/donors_choose_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['project_is_approved','teacher_prefix', 'school_state', 'project_submitted_datetime',\n",
    "           'project_grade_category', 'project_essay_1', 'teacher_number_of_previously_posted_projects']\n",
    "df = df[columns].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['project_submitted_datetime'] = [dateparse(i) for i in df.project_submitted_datetime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:44</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-08-12 15:42:11</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-08-06 09:09:11</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_is_approved teacher_prefix school_state project_submitted_datetime  \\\n",
       "0                    1            Ms.           NV        2016-11-18 14:45:59   \n",
       "1                    0           Mrs.           GA        2017-04-26 15:57:28   \n",
       "2                    1            Ms.           UT        2017-01-01 22:57:44   \n",
       "3                    0            Mr.           NC        2016-08-12 15:42:11   \n",
       "4                    1            Mr.           CA        2016-08-06 09:09:11   \n",
       "\n",
       "  project_grade_category                                    project_essay_1  \\\n",
       "0          Grades PreK-2  Most of my kindergarten students come from low...   \n",
       "1             Grades 3-5  Our elementary school is a culturally rich sch...   \n",
       "2             Grades 3-5  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3             Grades 3-5  My students are the greatest students but are ...   \n",
       "4             Grades 6-8  My students are athletes and students who are ...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  \n",
       "0                                            26  \n",
       "1                                             1  \n",
       "2                                             5  \n",
       "3                                            16  \n",
       "4                                            42  "
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Maybe You Can Add More Dates\n",
    "\n",
    "df['year'] = [i.year for i in df.project_submitted_datetime]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_accuracy = df.project_is_approved.value_counts().iloc[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8510"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.project_is_approved.value_counts().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1baa9d47f0>"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.school_state.value_counts().head(10).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2016    7271\n",
       "2017    2729\n",
       "Name: school_state, dtype: int64"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('year').school_state.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How Will Month Look Like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['project_essay_1']\n",
    "\n",
    "X = text\n",
    "y = df.project_is_approved\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(vect, weights = {1: 1, 0: 1}):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    #print(('Features: ', X_train_dtm.shape[1]))\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    nb = RandomForestClassifier(class_weight = weights)\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    return nb,  metrics.accuracy_score(y_test, y_pred_class) , X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>049</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zoos</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>àll</th>\n",
       "      <th>سلام</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  00am  00pm  02  03  049  05  10  100  ...   zombie  zone  zoned  \\\n",
       "0   0    0     0     0   0   0    0   0   0    0  ...        0     0      0   \n",
       "1   0    0     0     0   0   0    0   0   0    0  ...        0     0      0   \n",
       "2   0    0     0     0   0   0    0   0   0    0  ...        0     0      0   \n",
       "3   0    0     0     0   0   0    0   0   0    0  ...        0     0      0   \n",
       "4   0    0     0     0   0   0    0   0   0    0  ...        0     0      0   \n",
       "\n",
       "   zones  zoo  zooming  zoos  zuckerberg  àll  سلام  \n",
       "0      0    0        0     0           0    0     0  \n",
       "1      0    0        0     0           0    0     0  \n",
       "2      0    0        0     0           0    0     0  \n",
       "3      0    0        0     0           0    0     0  \n",
       "4      0    0        0     0           0    0     0  \n",
       "\n",
       "[5 rows x 13100 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train_count = vect.fit_transform(X_train)\n",
    "pd.DataFrame(X_train_count.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model, accuracy, transformed = accuracy_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Below Accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11355</th>\n",
       "      <td>students</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10403</th>\n",
       "      <td>school</td>\n",
       "      <td>0.004350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>and</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12921</th>\n",
       "      <td>with</td>\n",
       "      <td>0.003512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>of</td>\n",
       "      <td>0.003474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11939</th>\n",
       "      <td>to</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11782</th>\n",
       "      <td>their</td>\n",
       "      <td>0.002999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8360</th>\n",
       "      <td>on</td>\n",
       "      <td>0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6628</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>are</td>\n",
       "      <td>0.002873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  importance\n",
       "11355  students    0.004562\n",
       "10403    school    0.004350\n",
       "815         and    0.004075\n",
       "12921      with    0.003512\n",
       "8318         of    0.003474\n",
       "11939        to    0.003102\n",
       "11782     their    0.002999\n",
       "8360         on    0.002896\n",
       "6628   learning    0.002877\n",
       "947         are    0.002873"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature': vect.get_feature_names(), \n",
    "              'importance': model.feature_importances_}).sort_values(by='importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words & Add Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['project_is_approved', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_essay_1', 'teacher_number_of_previously_posted_projects',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8510\n",
       "0    1490\n",
       "Name: project_is_approved, dtype: int64"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.project_is_approved.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7114093959731544"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8510./1490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "\n",
    "model, accuracy, transformed = accuracy_test(vect, {1: 1,0: 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_lemmas(text):\n",
    "    text = str(text).lower()\n",
    "    words = TextBlob(text).words\n",
    "    return [word.lemmatize() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=split_into_lemmas, stop_words='english')\n",
    "model, accuracy, transformed = accuracy_test(vect, {1: 1,0: 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(analyzer=split_into_lemmas, stop_words='english')\n",
    "model, accuracy, transformed = accuracy_test(vect, {1: 1,0: 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8376"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Can Try Min_df and Max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Other Columns Once You Pick The Best Way to Vectorize The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>26</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:44</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-08-12 15:42:11</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>16</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-08-06 09:09:11</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>42</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_is_approved teacher_prefix school_state project_submitted_datetime  \\\n",
       "0                    1            Ms.           NV        2016-11-18 14:45:59   \n",
       "1                    0           Mrs.           GA        2017-04-26 15:57:28   \n",
       "2                    1            Ms.           UT        2017-01-01 22:57:44   \n",
       "3                    0            Mr.           NC        2016-08-12 15:42:11   \n",
       "4                    1            Mr.           CA        2016-08-06 09:09:11   \n",
       "\n",
       "  project_grade_category                                    project_essay_1  \\\n",
       "0          Grades PreK-2  Most of my kindergarten students come from low...   \n",
       "1             Grades 3-5  Our elementary school is a culturally rich sch...   \n",
       "2             Grades 3-5  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3             Grades 3-5  My students are the greatest students but are ...   \n",
       "4             Grades 6-8  My students are athletes and students who are ...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  year  \n",
       "0                                            26  2016  \n",
       "1                                             1  2017  \n",
       "2                                             5  2017  \n",
       "3                                            16  2016  \n",
       "4                                            42  2016  "
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[[ 'teacher_prefix','project_grade_category' ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>teacher_prefix_Dr.</th>\n",
       "      <th>teacher_prefix_Mr.</th>\n",
       "      <th>teacher_prefix_Mrs.</th>\n",
       "      <th>teacher_prefix_Ms.</th>\n",
       "      <th>teacher_prefix_Teacher</th>\n",
       "      <th>project_grade_category_Grades 3-5</th>\n",
       "      <th>project_grade_category_Grades 6-8</th>\n",
       "      <th>project_grade_category_Grades 9-12</th>\n",
       "      <th>project_grade_category_Grades PreK-2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:44</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>NC</td>\n",
       "      <td>2016-08-12 15:42:11</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>My students are the greatest students but are ...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-08-06 09:09:11</td>\n",
       "      <td>Grades 6-8</td>\n",
       "      <td>My students are athletes and students who are ...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   project_is_approved teacher_prefix school_state project_submitted_datetime  \\\n",
       "0                    1            Ms.           NV        2016-11-18 14:45:59   \n",
       "1                    0           Mrs.           GA        2017-04-26 15:57:28   \n",
       "2                    1            Ms.           UT        2017-01-01 22:57:44   \n",
       "3                    0            Mr.           NC        2016-08-12 15:42:11   \n",
       "4                    1            Mr.           CA        2016-08-06 09:09:11   \n",
       "\n",
       "  project_grade_category                                    project_essay_1  \\\n",
       "0          Grades PreK-2  Most of my kindergarten students come from low...   \n",
       "1             Grades 3-5  Our elementary school is a culturally rich sch...   \n",
       "2             Grades 3-5  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "3             Grades 3-5  My students are the greatest students but are ...   \n",
       "4             Grades 6-8  My students are athletes and students who are ...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  teacher_prefix_Dr.  \\\n",
       "0                                            26                   0   \n",
       "1                                             1                   0   \n",
       "2                                             5                   0   \n",
       "3                                            16                   0   \n",
       "4                                            42                   0   \n",
       "\n",
       "   teacher_prefix_Mr.  teacher_prefix_Mrs.  teacher_prefix_Ms.  \\\n",
       "0                   0                    0                   1   \n",
       "1                   0                    1                   0   \n",
       "2                   0                    0                   1   \n",
       "3                   1                    0                   0   \n",
       "4                   1                    0                   0   \n",
       "\n",
       "   teacher_prefix_Teacher  project_grade_category_Grades 3-5  \\\n",
       "0                       0                                  0   \n",
       "1                       0                                  1   \n",
       "2                       0                                  1   \n",
       "3                       0                                  1   \n",
       "4                       0                                  0   \n",
       "\n",
       "   project_grade_category_Grades 6-8  project_grade_category_Grades 9-12  \\\n",
       "0                                  0                                   0   \n",
       "1                                  0                                   0   \n",
       "2                                  0                                   0   \n",
       "3                                  0                                   0   \n",
       "4                                  1                                   0   \n",
       "\n",
       "   project_grade_category_Grades PreK-2  \n",
       "0                                     1  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     0  \n",
       "4                                     0  "
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['project_essay_1'] + dummies.columns.tolist() ]\n",
    "y = df.project_is_approved\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize The Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=list(stop_words), analyzer=split_into_lemmas)\n",
    "X_train_dtm = vect.fit_transform(X_train.project_essay_1)\n",
    "X_test_dtm = vect.transform(X_test.project_essay_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine The Features and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "extra = sp.sparse.csr_matrix(X_train.drop('project_essay_1', axis=1).astype(float))\n",
    "X_train_dtm_extra = sp.sparse.hstack((X_train_dtm, extra))\n",
    "\n",
    "#Test Set\n",
    "extra = sp.sparse.csr_matrix(X_test.drop('project_essay_1', axis=1).astype(float))\n",
    "X_test_dtm_extra = sp.sparse.hstack((X_test_dtm, extra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificiation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernandohidalgo/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8388\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_dtm_extra, y_train)\n",
    "y_pred_class = rf.predict(X_test_dtm_extra)\n",
    "print((metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this case the text may not be predictive, there might other features that are more important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
